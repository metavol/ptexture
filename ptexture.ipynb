{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# ptexture project\n",
    "# 'PET texture analysis with Python'\n",
    "#\n",
    "#\n",
    "# Kenji Hirata, MD, PhD\n",
    "# Hokkaido University, Sapporo, Japan\n",
    "# khirata@med.hokudai.ac.jp\n",
    "# 1/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import queue\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Report function\n",
    "# Kenji Hirata, 1/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def do_not_report(obj):\n",
    "    pass\n",
    "\n",
    "def do_report(obj):\n",
    "    if type(obj) == pd.core.frame.DataFrame:\n",
    "        display(obj)\n",
    "    else:\n",
    "        print(obj)\n",
    "    return\n",
    "\n",
    "report = do_not_report\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Test data\n",
    "# Kenji Hirata, 11/21/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def data1():\n",
    "    data = np.array([\n",
    "      3,3,4,4,5,\n",
    "      3,3,4,3,5,\n",
    "      7,3,4,3,5,\n",
    "      3,3,4,4,5,\n",
    "      3,3,4,4,5,\n",
    "\n",
    "      6,2,2,4,5,\n",
    "      2,2,4,4,9,\n",
    "      2,7,9,9,4,\n",
    "      1,2,4,9,2,\n",
    "      2,1,4,2,9,\n",
    "\n",
    "      3,3,4,4,5,\n",
    "      3,9,4,4,5,\n",
    "      3,3,9,4,5,\n",
    "      3,8,4,4,5,\n",
    "      3,8,4,4,5\n",
    "    ])\n",
    "    m = data.reshape((3,5,5))\n",
    "    return m\n",
    "\n",
    "def data2():\n",
    "    data = np.array([\n",
    "      3,3,4,4,5,7,3,\n",
    "      3,3,4,3,5,5,3,\n",
    "      7,3,4,3,5,4,4,\n",
    "      3,3,4,4,5,4,4,\n",
    "      3,3,4,4,5,6,1])\n",
    "    m = data.reshape((5,7))\n",
    "    return m\n",
    "    \n",
    "    \n",
    "def data3():\n",
    "    data = np.array([\n",
    "        2,2,1,1,1,1,1,\n",
    "        1,1,1,1,7,1,2,\n",
    "        1,1,0,0,7,7,2,\n",
    "        2,2,2,2,2,3,3,\n",
    "        2,2,3,np.nan,3,4,4,\n",
    "        5,5,5,3,3,3,3,\n",
    "        3,3,3,3,3,2,3\n",
    "    ])\n",
    "    m = data.reshape((7,7))\n",
    "    return m\n",
    "\n",
    "def data4():\n",
    "    data = np.array([\n",
    "        1,1,1,1,7,\n",
    "        1,0,0,1,7,\n",
    "        1,1,2,2,np.nan,\n",
    "        2,2,3,np.nan,3,\n",
    "        5,5,5,3,3,\n",
    "    ])\n",
    "    m = data.reshape((5,5))\n",
    "    return m\n",
    "\n",
    "def data5():\n",
    "    np.random.seed(123)\n",
    "    data = np.random.rand(64)\n",
    "    m = data.reshape((8,8))\n",
    "    return m\n",
    "\n",
    "def data6():\n",
    "    df = pd.DataFrame({'x':[1,1,1,2,2,3,3,3], 'y':[1,2,3,1,2,1,2,3], 'v':[11,12,13,14,15,16,17,18]})\n",
    "    return df\n",
    "\n",
    "def data7():\n",
    "    data = (np.arange(16))**2/10 + 5\n",
    "    return data\n",
    "\n",
    "def data8():\n",
    "    df = pd.DataFrame({'x':[1,1,1,1,2,2,2,3,3,3,3,4,4,4,4], 'y':[1,2,3,4,1,2,3,1,2,3,4,1,2,3,4], 'v':[11,15,18,23,9,8,6,4,7,6,2,8,9,12,14]})\n",
    "    return df\n",
    "\n",
    "def data9():\n",
    "    df = pd.DataFrame({'x':[1,1,1,1,2,2,2,3,3,3,3,4,4,4,4],\n",
    "                       'y':[1,2,3,4,1,2,3,1,2,3,4,1,2,3,4],\n",
    "                       'v':[11.5,15.7,18.9,23.2,9.4,8.7,6.1,4.8,7.1,6.2,2.9,8.7,9.5,12.4,14.3]})\n",
    "    return df\n",
    "\n",
    "def data10():\n",
    "    df = pd.DataFrame({'x':[1,1,1,2,2,2,3,3],\n",
    "                       'y':[1,2,3,1,2,3,1,2],\n",
    "                       'v':[3.5, 5.5, 7.0, 3.0, 4.0, 2.0, 6, 5]})\n",
    "    return df\n",
    "\n",
    "def data11():\n",
    "    nx, ny, nz = 5, 4, 3\n",
    "    l = [(x,y,z) for z in range(nz) for y in range(ny) for x in range(nx)]\n",
    "    df = pd.DataFrame(l, columns=['x','y','z'])\n",
    "    df['v'] = df.index * 0.27\n",
    "    df2 = df.drop([18,20,59])\n",
    "    return df2\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# generate_ndarray\n",
    "# takes x,y,v DataFrame to generate numpy 2D array\n",
    "# takes x,y,z,v DataFrame to generate numpy 3D array\n",
    "#\n",
    "# Kenji Hirata, 1/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def generate_2darray(df):\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    m = np.empty((maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.y)- miny, int(a.x)- minx] = a.v\n",
    "    return m\n",
    "\n",
    "def generate_3darray(df):\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    minz = np.min(df.z)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    maxz = np.max(df.z)\n",
    "    m = np.empty((maxz - minz + 1, maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.z)- minz, int(a.y)- miny, int(a.x)- minx] = a.v\n",
    "    return m\n",
    "\n",
    "def generate_2darray_v1(df):\n",
    "    report('Generating 2-dimensional array')\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    m = np.empty((maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.y)- miny, int(a.x)- minx] = a.v1\n",
    "    return m\n",
    "\n",
    "def generate_3darray_v1(df):\n",
    "    report('Generating 3-dimensional array')\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    minz = np.min(df.z)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    maxz = np.max(df.z)\n",
    "    m = np.empty((maxz - minz + 1, maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.z)- minz, int(a.y)- miny, int(a.x)- minx] = a.v1\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# discritize\n",
    "# takes ndarray of continuous value, returns same size of ndarray of nbin levels decrete value.\n",
    "# The input ndarray may contain NaN.\n",
    "# The result type is 'ndarray of float' rather than int because NaN does not exist in int type.\n",
    "#\n",
    "# Kenji Hirata, 11/21/2017\n",
    "# modified on 12/04\n",
    "#\n",
    "################################################\n",
    "\n",
    "def discritize(data, nbin, lo, hi, getCategories = False):\n",
    "    '''If you want lo and hi to be min and max of the data, respectively,\n",
    "    give np.nan for both lo and hi.\n",
    "    '''\n",
    "    if np.isnan(lo):\n",
    "        lo = np.nanmin(data.ravel())\n",
    "    if np.isnan(hi):\n",
    "        hi = np.nanmax(data.ravel())\n",
    "    \n",
    "    if lo > hi:\n",
    "        raise ValueError('lo must not be higher than hi.')\n",
    "    \n",
    "    R = np.floor((nbin * (data - lo) / (hi-lo)))\n",
    "    R[R < 0] = 0\n",
    "    R[R >= nbin] = nbin -1\n",
    "\n",
    "    cats = np.array([(hi - lo) / nbin * i + lo for i in range(nbin+1)])\n",
    "    report(('bins', nbin))\n",
    "    report(('categories', cats))\n",
    "    \n",
    "    if getCategories:\n",
    "        return R, cats\n",
    "    else:\n",
    "        return R \n",
    "\n",
    "    \n",
    "################################################\n",
    "#\n",
    "# complement_crosstab\n",
    "#\n",
    "# Kenji Hirata, 11/21/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def complement_crosstab2(cr, index_hi=np.nan, column_hi=np.nan):\n",
    "    if np.isnan(index_hi):\n",
    "        index_hi = int(np.max(cr.index.values)+1)\n",
    "    if np.isnan(column_hi):\n",
    "        column_hi = int(np.max(cr.columns.values)+1)\n",
    "    d = pd.DataFrame(np.zeros((index_hi, column_hi)), index=np.arange(index_hi), columns=np.arange(column_hi))\n",
    "    cr1 = cr.add(d, fill_value=0)\n",
    "    return cr1\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Usual parameters in Python\n",
    "# Kenji Hirata, 11/22/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def usualParams(v):\n",
    "    report('### Calculating usual parameters')\n",
    "    \n",
    "    SUVmax = max(v)\n",
    "    SUVmean = np.mean(v)\n",
    "    n = len(v) * 1*1*1\n",
    "    s = np.sum(v)\n",
    "    cols = ['SUVmax', 'SUVmean', 'NumOfVoxels', 'SUVsum']\n",
    "    vals = [[SUVmax, SUVmean, n, s]]\n",
    "    results = pd.DataFrame(data=vals, columns=cols)\n",
    "\n",
    "    report(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Usual parameters in Python\n",
    "# Kenji Hirata, 11/22/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def histParams(hist):\n",
    "    report('### Calculating histogram parameters')\n",
    "    \n",
    "    SDhist = np.std(hist, ddof=1)\n",
    "    \n",
    "    #Skewness = (1/N)*np.sum((h-np.mean(h))**3) / ((1/N)*np.sum((h-np.mean(h))**2))**(3/2)\n",
    "    Skewness = scipy.stats.skew(hist)\n",
    "    \n",
    "    #Kurtosis = (1/N)*np.sum((h-np.mean(h))**4) / ((1/N)*np.sum((h-np.mean(h))**2))**2 - 3\n",
    "    Kurtosis = scipy.stats.kurtosis(hist)\n",
    "    \n",
    "    tb = pd.crosstab(hist,0)\n",
    "    p = complement_crosstab2(tb).values.ravel()/len(hist)\n",
    "    #print('Probability of gray-level i', p)\n",
    "    EnergyHist = np.sum(p*p)\n",
    "    \n",
    "    p_nz = p[p != 0]\n",
    "    EntropyHist = -np.sum(p_nz*np.log(p_nz))\n",
    "    \n",
    "    cols = ['SDhist', 'Skewness', 'Kurtosis', 'EnergyHist', 'EntropyHist']\n",
    "    vals = [[SDhist, Skewness, Kurtosis, EnergyHist, EntropyHist]]\n",
    "    results = pd.DataFrame(data=vals, columns=cols)\n",
    "\n",
    "    report(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Gray-level co-occurrence matrix (GLCM) based texture parameters in Python\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def comat2d(d, offset, nbin):\n",
    "    d1 = pd.DataFrame({'v2': d.v1, 'y': d.y - offset[0],  'x': d.x + offset[1]})\n",
    "    d2 = pd.merge(d,d1)\n",
    "    cr = pd.crosstab(d2.v1, d2.v2)\n",
    "    cr1 = complement_crosstab2(cr, nbin, nbin)\n",
    "    return cr1, d2\n",
    "\n",
    "def comat3d(d, offset, nbin):\n",
    "    d1 = pd.DataFrame({'v2': d.v1, 'z': d.z - offset[0], 'y': d.y - offset[1], 'x': d.x - offset[2]})\n",
    "    # subtracting offset may look tricky; with this operation current(v1) and (current + offset)(v2) are paired.\n",
    "    d2 = pd.merge(d,d1)\n",
    "    cr = pd.crosstab(d2.v1, d2.v2)\n",
    "    cr1 = complement_crosstab2(cr, nbin, nbin)\n",
    "    return cr1, d2\n",
    "\n",
    "def comatParams2d(d, nbin):\n",
    "    offsets = fourDirections()\n",
    "    return comatParams(d,nbin,offsets)\n",
    "    \n",
    "def comatParams3d(d, nbin):\n",
    "    offsets = thirteenDirections()\n",
    "    return comatParams(d,nbin,offsets)\n",
    "\n",
    "def fourDirections():\n",
    "    return [(0,1), (1,0), (1,1), (1,-1)]\n",
    "\n",
    "def thirteenDirections():\n",
    "    return [(0,0,1), (0,1,1), (0,1,0), (0,1,-1),\n",
    "            (1,0,0), (1,0,1), (1,1,1), (1,1,0),\n",
    "            (1,1,-1), (1,0,-1),(1,-1,-1),(1,1,0),(1,-1,1)]\n",
    "\n",
    "    # The total of 13 directions mean as follows:\n",
    "    #\n",
    "    # (0,0,1)  3 o'clock\n",
    "    # (0,1,1)　4:30 o'clock\n",
    "    # (0,1,0)　6 o'clock\n",
    "    # (0,1,-1) 7:30 o'clock\n",
    "    #  9  o'clock and later are omitted because it already appreared.\n",
    "    # \n",
    "    #  Downward direction (delta z=1)\n",
    "    # (1,0,0) center of the clock\n",
    "    # (1,0,1) 3 o'clock\n",
    "    # (1,1,1) 4:30 o'clock\n",
    "    # (1,1,0) 6 o'clock\n",
    "    # (1,1,-1) 7.5 o'clock\n",
    "    # (1,0,-1) 9 o'clock\n",
    "    # (1,-1,-1) 10:30 o'clock\n",
    "    # (1,1,0) 12 o'clock\n",
    "    # (1,-1,1) 1:30 o'clock\n",
    "            \n",
    "def comatParams(d, nbin, offsets):\n",
    "    report('### Generating Co-occurence matrix')\n",
    "\n",
    "    dim = len(offsets[0])\n",
    "    seq = np.arange(nbin)\n",
    "    ii = np.tile(seq, (nbin,1))\n",
    "    jj = ii.T\n",
    "    lst =[]\n",
    "\n",
    "    for o in offsets:\n",
    "\n",
    "        if dim==2:\n",
    "            com, d2 = comat2d(d, o, nbin)\n",
    "        elif dim==3:\n",
    "            com, d2 = comat3d(d, o, nbin)\n",
    "        \n",
    "        report(('offset', o))\n",
    "        report(com)\n",
    "        cm = com.values\n",
    "        \n",
    "        cm = cm / np.sum(cm)\n",
    "        cm_nz = cm[cm != 0]\n",
    "        \n",
    "        homogeneity = np.sum(cm / (1+np.abs(ii-jj)))\n",
    "        energy = np.sum(cm**2)\n",
    "        correlation = np.corrcoef(d2.v1, d2.v2)[0,1]\n",
    "        \n",
    "        contrast = np.sum((ii-jj)**2*cm)\n",
    "        entropy = -np.sum(cm_nz * np.log(cm_nz))\n",
    "        dissimilarity = np.sum(np.abs(ii-jj)*cm)\n",
    "\n",
    "        ids = ['HomogeneityGLCM','EnergyGLCM','CorrelationGLCM','ContrastGLCM','EntropyGLCM','DissimilarityGLCM']\n",
    "        se=pd.Series([homogeneity, energy, correlation, contrast, entropy, dissimilarity], ids)\n",
    "        \n",
    "        if dim==2:\n",
    "            se.name = (o[0]+1, o[1]+1)\n",
    "        elif dim==3:\n",
    "            se.name = (o[0]+1, o[1]+1, o[2]+1)\n",
    "\n",
    "        lst.append(se)\n",
    "        \n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    report(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# gray-level run-length matrix\n",
    "# Kenji Hirata, 11/23/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def xline(x, m):\n",
    "    ny,nx = m.shape\n",
    "    return [(y,x) for y in range(ny)]\n",
    "\n",
    "def yline(y, m):\n",
    "    ny,nx = m.shape\n",
    "    return [(y,x) for x in range(nx)]\n",
    "\n",
    "def xplain(x, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for z in range(nz) for y in range(ny)]\n",
    "\n",
    "def yplain(y, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for z in range(nz) for x in range(nx)]\n",
    "\n",
    "def zplain(z, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for y in range(ny) for x in range(nx)]\n",
    "\n",
    "\n",
    "def rle(vec):\n",
    "    if len(vec)==0:\n",
    "        return [],[]\n",
    "    if len(vec)==1:\n",
    "        return vec,[1]\n",
    "    \n",
    "    prev = vec[0]\n",
    "    count = 1\n",
    "    vallst = []\n",
    "    lenlst = []\n",
    "    for a in vec[1:]:\n",
    "        if (a == prev) or (np.isnan(a) and np.isnan(prev)):\n",
    "            count += 1\n",
    "        else:\n",
    "            vallst.append(prev)\n",
    "            lenlst.append(count)\n",
    "            count = 1\n",
    "            prev = a\n",
    "    else:\n",
    "        vallst.append(a)\n",
    "        lenlst.append(count)\n",
    "    return vallst,lenlst\n",
    "\n",
    "def getGlrlm2d(discritizedArray, initialpoints, dy, dx):\n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    a1d =[]\n",
    "    for current in initialpoints:\n",
    "        cy,cx = current\n",
    "        while((cy >= 0) and (cx >= 0) and (cy < ny) and (cx < nx)):\n",
    "            a1d.append(m[cy,cx])\n",
    "            cx += dx\n",
    "            cy += dy\n",
    "        a1d.append(np.nan)\n",
    "    vals, lens = rle(a1d)\n",
    "    \n",
    "    flag = ~np.isnan(vals)\n",
    "    vals1 = np.array(vals)[flag].astype(int)\n",
    "    lens1 = np.array(lens)[flag]\n",
    "    cr = pd.crosstab(vals1,lens1)\n",
    "    cr1 = complement_crosstab2(cr)\n",
    "    return cr1\n",
    "\n",
    "def getGlrlm3d(discritizedArray, initialpoints, dz, dy, dx):\n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    a1d =[]\n",
    "    for current in initialpoints:\n",
    "        cz,cy,cx = current\n",
    "        while((cz >= 0) and (cy >= 0) and (cx >= 0) and (cz < nz) and (cy < ny) and (cx < nx)):\n",
    "            a1d.append(m[cz,cy,cx])\n",
    "            cx += dx\n",
    "            cy += dy\n",
    "            cz += dz\n",
    "        a1d.append(np.nan)\n",
    "    vals, lens = rle(a1d)\n",
    "    \n",
    "    flag = ~np.isnan(vals)\n",
    "    vals1 = np.array(vals)[flag].astype(int)\n",
    "    lens1 = np.array(lens)[flag]\n",
    "    cr = pd.crosstab(vals1,lens1)\n",
    "    cr1 = complement_crosstab2(cr)\n",
    "    return cr1\n",
    "\n",
    "\n",
    "def calcGlrlmParams(glrlm_or_glszm, mode):\n",
    "    '''mode is either 'R' or 'Z'\n",
    "    'R' indicates GLRLM, and 'Z' indicates GLSZM.\n",
    "    The calculation formulas are completely same between 'R' and 'Z';\n",
    "    the only difference is variable name (i.e., index of the returning pd.Series)\n",
    "    '''\n",
    "    \n",
    "    # left-most column indicating number of run(size)=0 must be removed because it is unnecessary and even causes an adverse effect of divided-by-zero error.\n",
    "    mat = glrlm_or_glszm.values[:,1:]\n",
    "\n",
    "    sh = mat.shape\n",
    "    jj = np.tile(np.arange(sh[1])+1, (sh[0],1))\n",
    "    ii = np.tile(np.arange(sh[0])+1, (sh[1],1)).T\n",
    "    \n",
    "    SRE   = (1/np.sum(mat)) * np.sum(mat/jj**2)\n",
    "    LRE   = (1/np.sum(mat)) * np.sum(mat*jj**2)\n",
    "    LGRE  = (1/np.sum(mat)) * np.sum(mat/ii**2)\n",
    "    HGRE  = (1/np.sum(mat)) * np.sum(mat*ii**2)\n",
    "    SRLGE = (1/np.sum(mat)) * np.sum(mat/ii**2/jj**2)\n",
    "    SRHGE = (1/np.sum(mat)) * np.sum(mat*ii**2/jj**2)\n",
    "    LRLGE = (1/np.sum(mat)) * np.sum(mat/ii**2*jj**2)\n",
    "    LRHGE = (1/np.sum(mat)) * np.sum(mat*ii**2*jj**2)\n",
    "    GLNUr = (1/np.sum(mat)) * np.sum(np.sum(mat, axis=1)**2)\n",
    "    RLNU  = (1/np.sum(mat)) * np.sum(np.sum(mat, axis=0)**2)\n",
    "    RP    = np.sum(mat) / np.sum(jj * mat)\n",
    "\n",
    "    if mode == 'R':\n",
    "        ids = ['SRE', 'LRE', 'LGRE', 'HGRE', 'SRLGE', 'SRHGE', 'LRLGE', 'LRHGE', 'GLNUr', 'RLNU', 'RP']\n",
    "    if mode == 'Z':\n",
    "        ids = ['SZE', 'LZE', 'LGZE', 'HGZE', 'SZLGE', 'SZHGE', 'LZLGE', 'LZHGE', 'GLNUz', 'ZLNU', 'ZP']\n",
    "\n",
    "    se = pd.Series([SRE, LRE, LGRE, HGRE, SRLGE, SRHGE, LRLGE, LRHGE, GLNUr, RLNU, RP], ids)\n",
    "    return se\n",
    "\n",
    "\n",
    "        \n",
    "def combineGlrlm2d(discritizedArray):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    lst =[]\n",
    "\n",
    "    def sub(m, points, dy, dx):\n",
    "        g = getGlrlm2d(m, points, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str((dy+1,dx+1))\n",
    "        lst.append(se)\n",
    "    \n",
    "    points = xline(0, m)\n",
    "    sub(m, points, 0, 1)\n",
    "\n",
    "    points = yline(0, m)\n",
    "    sub(m, points, 1, 0)\n",
    "\n",
    "    points = set(xline(0, m)) | set(yline(0, m))\n",
    "    sub(m, points, 1, 1)\n",
    "\n",
    "    points = set(xline(0, m)) | set(yline(nx-1, m))\n",
    "    sub(m, points, -1, 1)\n",
    "    \n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    report(df)\n",
    "    return df\n",
    "\n",
    "def combineGlrlm3d(discritizedArray):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    lst =[]\n",
    "    \n",
    "    def sub(m, points, dz, dy, dx):\n",
    "        g = getGlrlm3d(m, points, dz, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str((dz+1,dy+1,dx+1))\n",
    "        lst.append(se)\n",
    "        \n",
    "    ###\n",
    "    points = xplain(0, m)\n",
    "    sub(m, points, 0, 0, 1)\n",
    "    \n",
    "    points = yplain(0, m)\n",
    "    sub(m, points, 0, 1, 0)\n",
    "    \n",
    "    points = zplain(0, m)\n",
    "    sub(m, points, 1, 0, 0)\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m))\n",
    "    sub(m, points, 0, 1, 1)\n",
    "\n",
    "    points = set(yplain(0, m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, 1, 0)\n",
    "\n",
    "    points = set(zplain(0, m)) | set(xplain(0,m))\n",
    "    sub(m, points, 1, 0, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(ny-1,m))\n",
    "    sub(m, points, 0, -1, 1)\n",
    "\n",
    "    points = set(yplain(0, m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, 1, 0)\n",
    "\n",
    "    points = set(zplain(0, m)) | set(xplain(nx-1,m))\n",
    "    sub(m, points, 1, 0, -1)\n",
    "    ###\n",
    "\n",
    "    ###\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, 1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, 1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(ny-1,m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, -1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, 1, 1)\n",
    "    ###\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    return df\n",
    "\n",
    "def combineGlrlm(discritizedArray):\n",
    "    \n",
    "    report('### Generating GLRLM')\n",
    "    \n",
    "    if len(discritizedArray.shape) == 2:\n",
    "        df = combineGlrlm2d(discritizedArray)\n",
    "    elif len(discritizedArray.shape) == 3:\n",
    "        df = combineGlrlm3d(discritizedArray)\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "    report(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# gray-level zone-size matrix in Python\n",
    "# Kenji Hirata, 11/24/2017\n",
    "#\n",
    "################################################\n",
    "    \n",
    "def getGlzsm(discritizedArray, connection):\n",
    "    m = discritizedArray\n",
    "    if len(m.shape) == 2:\n",
    "        if connection == 4:\n",
    "            s = [[0,1,0],[1,1,1],[0,1,0]]\n",
    "        elif connection == 8:\n",
    "            s = [[1]*3]*3\n",
    "        else:\n",
    "            raise ValueError('connection must be 4 or 8 in case of 2-dimensional.')\n",
    "    elif len(m.shape) == 3:\n",
    "        if connection == 6:\n",
    "            s = [[[0,0,0], [0,1,0], [0,0,0]],\n",
    "                 [[0,1,0], [1,1,1], [0,1,0]],\n",
    "                 [[0,0,0], [0,1,0], [0,0,0]]]\n",
    "        elif connection == 18:\n",
    "            s = [[[0,1,0], [1,1,1], [0,1,0]],\n",
    "                 [[1,1,1], [1,1,1], [1,1,1]],\n",
    "                 [[0,1,0], [1,1,1], [0,1,0]]]\n",
    "        elif connection == 26:\n",
    "            s = [[[1]*3]*3]*3\n",
    "        else:\n",
    "            raise ValueError('connection must be 6 or 18 or 26 in case of 3-dimensional.')\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "    lst = []\n",
    "    maxgl = np.nanmax(m).astype(int)\n",
    "    maxsz = 0\n",
    "    for i in range(maxgl+1):#[2,3]:\n",
    "\n",
    "        m1 = m==i\n",
    "        a,_ = scipy.ndimage.label(m1, s)\n",
    "        if np.sum(a)==0:\n",
    "            continue\n",
    "        b=pd.crosstab(a.flatten(), 0)\n",
    "        c = pd.crosstab(b[1:].values.flatten(), 0)\n",
    "        c.columns = [[i]]\n",
    "        c = c.T\n",
    "\n",
    "        maxsz1 = np.max(c.columns.values)\n",
    "        if maxsz < maxsz1:\n",
    "            maxsz = maxsz1\n",
    "\n",
    "        lst.append(c)\n",
    "    \n",
    "    df = pd.DataFrame(np.zeros((maxgl+1,maxsz+1)), index = np.arange(maxgl+1), columns=np.arange(maxsz+1))\n",
    "    for l in lst:\n",
    "        df = df.add(l, fill_value =0)\n",
    "    df = df.astype(int)\n",
    "    return df\n",
    "\n",
    "def combineGlzsm(discritizedArray, connection):\n",
    "    report('### Generating GLZSM')\n",
    "\n",
    "    m = discritizedArray\n",
    "    df = getGlzsm(m, connection)\n",
    "    report(df)\n",
    "    ps = calcGlrlmParams(df, 'Z')\n",
    "    res = pd.DataFrame([ps])\n",
    "    report(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# neighborhood gray-level different matrix in Python\n",
    "# Kenji Hirata, 11/27/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def getNgldm(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    if len(m.shape) == 2:\n",
    "        return getNgldm2d(discritizedArray, mode)\n",
    "    elif len(m.shape) == 3:\n",
    "        return getNgldm3d(discritizedArray, mode)\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "def getNgldm2d(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    \n",
    "    #fill periphery with numpy.nan\n",
    "    nx+=2\n",
    "    ny+=2\n",
    "    m1 = np.empty((ny,nx))\n",
    "    m1.fill(np.nan)\n",
    "    m1[1:-1,1:-1] = m\n",
    "    m = m1\n",
    "\n",
    "    se = pd.Series()\n",
    "    for i in range(int(np.nanmax(m)+1)):\n",
    "        #print('i =',i)\n",
    "        avelist = []\n",
    "        for y in range(1,ny-1):\n",
    "            for x in range(1,nx-1):\n",
    "                if np.isnan(m[y,x]) == False:\n",
    "                    if m[y,x] == i:\n",
    "                        neighbors = [m[y-1,x-1], m[y-1,x  ], m[y-1,x+1],\n",
    "                                     m[y  ,x-1],             m[y  ,x+1],\n",
    "                                     m[y+1,x-1], m[y+1,x  ], m[y+1,x+1]]\n",
    "                        if mode == 1:\n",
    "                            ave = np.nanmean(neighbors)\n",
    "                        elif mode == 2:\n",
    "                            ave = np.mean(neighbors)\n",
    "                        #print(x,y,'ave =',ave)\n",
    "                        avelist.append(np.abs(i - ave))\n",
    "        sum = np.nansum(avelist) # not mean but sum\n",
    "        se1 = pd.Series({i:sum})\n",
    "        se = se.append(se1)\n",
    "    return se\n",
    "\n",
    "def getNgldm3d(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    \n",
    "    #fill periphery with numpy.nan\n",
    "    nz+=2\n",
    "    ny+=2\n",
    "    nx+=2    \n",
    "    m1 = np.empty((nz,ny,nx))\n",
    "    m1.fill(np.nan)\n",
    "    m1[1:-1,1:-1,1:-1] = m\n",
    "    m = m1\n",
    "\n",
    "    se = pd.Series()\n",
    "    for i in range(int(np.nanmax(m)+1)):\n",
    "        avelist = []\n",
    "        for z in range(1,nz-1):\n",
    "            for y in range(1,ny-1):\n",
    "                for x in range(1,nx-1):\n",
    "                    if np.isnan(m[z,y,x]) == False:\n",
    "                        if m[z,y,x] == i:\n",
    "                            neighbors = [m[z-1,y-1,x-1], m[z-1,y-1,x  ], m[z-1,y-1,x+1],\n",
    "                                         m[z-1,y  ,x-1], m[z-1,y  ,x  ], m[z-1,y  ,x+1],\n",
    "                                         m[z-1,y+1,x-1], m[z-1,y+1,x  ], m[z-1,y+1,x+1],\n",
    "                                         m[z  ,y-1,x-1], m[z  ,y-1,x  ], m[z  ,y-1,x+1],\n",
    "                                         m[z  ,y  ,x-1],                 m[z  ,y  ,x+1],\n",
    "                                         m[z  ,y+1,x-1], m[z  ,y+1,x  ], m[z  ,y+1,x+1],\n",
    "                                         m[z+1,y-1,x-1], m[z+1,y-1,x  ], m[z+1,y-1,x+1],\n",
    "                                         m[z+1,y  ,x-1], m[z+1,y  ,x  ], m[z+1,y  ,x+1],\n",
    "                                         m[z+1,y+1,x-1], m[z+1,y+1,x  ], m[z+1,y+1,x+1]]\n",
    "                            if mode == 1:\n",
    "                                ave = np.nanmean(neighbors)\n",
    "                            elif mode == 2:\n",
    "                                ave = np.mean(neighbors)\n",
    "                            avelist.append(np.abs(i - ave))\n",
    "        sum = np.nansum(avelist) # not mean but sum\n",
    "        se1 = pd.Series({i:sum})\n",
    "        se = se.append(se1)\n",
    "    return se\n",
    "\n",
    "\n",
    "def calcNgldmParams(discritizedArray, ngldm, nbin):\n",
    "    \n",
    "    p1 = pd.crosstab(discritizedArray.ravel(),0)\n",
    "    p = complement_crosstab2(p1, nbin).values.ravel()\n",
    "    N = np.sum(p)\n",
    "    p = p/N\n",
    "    \n",
    "    s = complement_crosstab2(pd.DataFrame(ngldm), nbin).values.ravel()\n",
    "\n",
    "    jj = np.tile(np.arange(nbin),(nbin,1))\n",
    "    ii = jj.T\n",
    "\n",
    "    report('NGLDM')\n",
    "    report(s)\n",
    "    report('probability')\n",
    "    report(p)\n",
    "\n",
    "    Coarseness = 1 / (1e-20 + np.sum(p*s))\n",
    "\n",
    "    Contrast = np.sum(np.outer(p,p) * (ii-jj)**2) * np.sum(s) / (N*nbin*(nbin-1))\n",
    "    \n",
    "    #busyness\n",
    "    total = 0\n",
    "    for i in range(len(p)):\n",
    "        for j in range(len(p)):\n",
    "            if not(p[i]==0) and not(p[j]==0):\n",
    "                total += np.abs(i * p[i] - j * p[j])\n",
    "    Busyness = np.sum(p*s) / total\n",
    "\n",
    "    se = pd.Series([Coarseness,Contrast,Busyness], ['CoarsenessNGLDM','ContrastNGLDM','BusynessNGLDM'])\n",
    "    return pd.DataFrame([se])\n",
    "\n",
    "def combineNgldm(mat, nbin, mode):\n",
    "    report('### Generating NGLDM')\n",
    "    ngldm = getNgldm(mat, mode)\n",
    "    res = calcNgldmParams(mat, ngldm, nbin)\n",
    "    report(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Get all params\n",
    "# Takes DataFrame with columns of x,y,v --- v is continuous\n",
    "#       nbin = 16, 32, 64, etc\n",
    "# Returns DataFrame\n",
    "#\n",
    "# Kenji Hirata, 11/27/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    results.append(usualParams(df.v))\n",
    "    \n",
    "    df['v1'] = discritize(df.v, nbin, lo, hi)\n",
    "    results.append(histParams(df.v1))\n",
    "    \n",
    "    results.append(comatParams2d(df, nbin)) # comatParams requires v1 columns, which is discreted version of v.\n",
    "    \n",
    "    mat = generate_2darray_v1(df)\n",
    "    results.append(combineGlrlm(mat))\n",
    "    \n",
    "    results.append(combineGlzsm(mat, connection))\n",
    "    \n",
    "    results.append(combineNgldm(mat, nbin, ngldm_mode))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    results.append(usualParams(df.v))\n",
    "    \n",
    "    df['v1'] = discritize(df.v, nbin, lo, hi)\n",
    "    results.append(histParams(df.v1))\n",
    "    \n",
    "    results.append(comatParams3d(df, nbin)) # comatParams requires v1 columns, which is discreted version of v.\n",
    "    \n",
    "    mat = generate_3darray_v1(df)\n",
    "               \n",
    "    results.append(combineGlrlm(mat))\n",
    "    \n",
    "    results.append(combineGlzsm(mat, connection))\n",
    "\n",
    "    results.append(combineNgldm(mat, nbin, ngldm_mode))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "#\n",
    "# Convert ugly table to pretty table\n",
    "# Takes list of DataFrame\n",
    "# Returns DataFrame\n",
    "#\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def convertToPrettyTable(res):\n",
    "    res1 = []\n",
    "    for r in res:\n",
    "        if len(r)==1:\n",
    "            res1.append(r)\n",
    "        else:\n",
    "            s = r.iloc[-1,:]\n",
    "            d = pd.DataFrame([s], index=[0])\n",
    "            res1.append(d)\n",
    "    return pd.concat(res1, axis=1)\n",
    "\n",
    "def convertToPrettyTable2(res):\n",
    "    res1 = []\n",
    "    for r in res:\n",
    "        if len(r)==1:\n",
    "            res1.append(r)\n",
    "        else:\n",
    "            res1.append(stack1(r))\n",
    "    return pd.concat(res1, axis=1)\n",
    "\n",
    "\n",
    "def stack1(df):\n",
    "    b=df.stack()\n",
    "\n",
    "    def f(s):\n",
    "        return str(s).replace('(','').replace(')','').replace(' ','').replace(',','')\n",
    "\n",
    "    return pd.DataFrame([b.values], columns= [ind[1]+f(ind[0]) for ind in b.index])\n",
    "\n",
    "\n",
    "###################################################\n",
    "#\n",
    "# Super batch for texture analyses in Python\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "###################################################\n",
    "\n",
    "\n",
    "def superBatch(di, dim, nbin, lo, hi, connection, ngldm_mode, full = False):\n",
    "\n",
    "    filenames = os.listdir(di)\n",
    "\n",
    "    print(\"Files:\", filenames)\n",
    "    lst = []\n",
    "    for f in filenames:\n",
    "        print(str(datetime.datetime.now()), f)\n",
    "        \n",
    "        fullname = os.path.join(di,f)\n",
    "        \n",
    "        df = pd.read_csv(fullname, delimiter='\\t')\n",
    "        \n",
    "        \n",
    "        ##### temporary code\n",
    "        ###df.columns = ['x','y','z','v']\n",
    "        #####\n",
    "\n",
    "        if dim==2:\n",
    "            results = getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        elif dim==3:\n",
    "            results = getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        else:\n",
    "            raise ValueError('dim (dimension) must be 2 or 3.')\n",
    "            \n",
    "        if full:\n",
    "            results_pretty = convertToPrettyTable2(results)\n",
    "        else:\n",
    "            results_pretty = convertToPrettyTable(results)\n",
    "        \n",
    "        #print(results_pretty.T)\n",
    "        \n",
    "        results_pretty.index = [f]\n",
    "        \n",
    "        lst.append(results_pretty)\n",
    "\n",
    "    results_final = pd.concat(lst)\n",
    "    return results_final\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "#\n",
    "# Super batch 2 for texture analyses in Python\n",
    "# Kenji Hirata, 12/22/2017\n",
    "#\n",
    "###################################################\n",
    "\n",
    "\n",
    "def superBatch2(di, dim, nbin, lo, hi, connection, ngldm_mode):\n",
    "\n",
    "    filenames = os.listdir(di)\n",
    "\n",
    "    print(\"Files:\", filenames)\n",
    "    lst = []\n",
    "    for f in filenames:\n",
    "        print(str(datetime.datetime.now()))\n",
    "        print(f)\n",
    "        \n",
    "        fullname = os.path.join(di,f)\n",
    "        \n",
    "        df = pd.read_csv(fullname, delimiter='\\t')\n",
    "        \n",
    "        \n",
    "        ##### temporary code\n",
    "        \n",
    "        df.rename(columns = {'v1':'v'}, inplace=True)\n",
    "        df = df[['x','y','z','v']]\n",
    "        #print(df)\n",
    "        \n",
    "        #df.columns = ['roinum','x','y','z','v','fmiso','gd','flair']\n",
    "        #####\n",
    "\n",
    "        if dim==2:\n",
    "            results = getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        elif dim==3:\n",
    "            results = getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        else:\n",
    "            raise ValueError('dim (dimension) must be 2 or 3.')\n",
    "            \n",
    "        results_pretty = convertToPrettyTable(results)\n",
    "        print(results_pretty.T)\n",
    "        \n",
    "        results_pretty.index = [f]\n",
    "        \n",
    "        lst.append(results_pretty)\n",
    "\n",
    "    results_final = pd.concat(lst)\n",
    "    return results_final\n",
    "\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Template for Running ptexture\n",
    "\n",
    "\n",
    "# This indicates the directory where you have file(s) of x,y,z,v text.\n",
    "di = 'testdata'\n",
    "\n",
    "# Run\n",
    "# dim (dimention) is 2 or 3. 2 for polar map; 3 for volume data.\n",
    "# nbin is number of discritization bin, usually 64\n",
    "# lo and hi specifies lower and upper limit used for discritization\n",
    "#   if lo = np.nan and hi = np.nan, the global min and max are used for lo and hi.\n",
    "# connection must be 2 or 4 for 2-d, and 6, 18, or 26 for 3-d (detail will be explained later)\n",
    "# ngldm_mode = 1 uses np.nanmean(), mode == 2 uses np.mean() to calculate NGLDM\n",
    "df = superBatch(di, dim = 3, nbin = 64, lo = 0, hi = 20, connection = 26, ngldm_mode = 1)\n",
    "df.to_excel('result_file_name.xlsx')\n",
    "\n",
    "# min-max case\n",
    "#df = superBatch(di, dim = 3, nbin = 64, lo = np.nan, hi = np.nan, connection = 26, ngldm_mode = 1)\n",
    "#df.to_excel('result_file_name_minmax.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
