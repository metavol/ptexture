{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# PTexture project\n",
    "# 'PET texture analysis with Python'\n",
    "#\n",
    "# Kenji Hirata, MD, PhD\n",
    "# Hokkaido University, Sapporo, Japan\n",
    "# khirata@med.hokudai.ac.jp\n",
    "# Rev 8/30/2018\n",
    "# 1/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import queue\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "print('No error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Report function\n",
    "# Kenji Hirata, 1/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def do_not_report(obj):\n",
    "    pass\n",
    "\n",
    "def do_report(obj):\n",
    "    if type(obj) == pd.core.frame.DataFrame:\n",
    "        display(obj)\n",
    "    else:\n",
    "        print(obj)\n",
    "    return\n",
    "\n",
    "report = do_not_report\n",
    "#report = do_report\n",
    "\n",
    "print('No error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Test data\n",
    "# Kenji Hirata, 11/21/2017\n",
    "# 8/31/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def data1():\n",
    "    data = np.array([\n",
    "      3,3,4,4,5,\n",
    "      3,3,4,3,5,\n",
    "      7,3,4,3,5,\n",
    "      3,3,4,4,5,\n",
    "      3,3,4,4,5,\n",
    "\n",
    "      6,2,2,4,5,\n",
    "      2,2,4,4,9,\n",
    "      2,7,9,9,4,\n",
    "      1,2,4,9,2,\n",
    "      2,1,4,2,9,\n",
    "\n",
    "      3,3,4,4,5,\n",
    "      3,9,4,4,5,\n",
    "      3,3,9,4,5,\n",
    "      3,8,4,4,5,\n",
    "      3,8,4,4,5\n",
    "    ])\n",
    "    m = data.reshape((3,5,5))\n",
    "    return m\n",
    "\n",
    "\n",
    "def data2():\n",
    "    data = np.array([\n",
    "      3,3,4,4,5,7,3,\n",
    "      3,3,4,3,5,5,3,\n",
    "      7,3,4,3,5,4,4,\n",
    "      3,3,4,4,5,4,4,\n",
    "      3,3,4,4,5,6,1])\n",
    "    m = data.reshape((5,7))\n",
    "    return m\n",
    "    \n",
    "    \n",
    "def data3():\n",
    "    data = np.array([\n",
    "        2,2,1,1,1,1,1,\n",
    "        1,1,1,1,7,1,2,\n",
    "        1,1,0,0,7,7,2,\n",
    "        2,2,2,2,2,3,3,\n",
    "        2,2,3,np.nan,3,4,4,\n",
    "        5,5,5,3,3,3,3,\n",
    "        3,3,3,3,3,2,3\n",
    "    ])\n",
    "    m = data.reshape((7,7))\n",
    "    return m\n",
    "\n",
    "\n",
    "def data4():\n",
    "    data = np.array([\n",
    "        1,1,1,1,7,\n",
    "        1,0,0,1,7,\n",
    "        1,1,2,2,np.nan,\n",
    "        2,2,3,np.nan,3,\n",
    "        5,5,5,3,3,\n",
    "    ])\n",
    "    m = data.reshape((5,5))\n",
    "    return m\n",
    "\n",
    "\n",
    "def data5():\n",
    "    np.random.seed(123)\n",
    "    data = np.random.rand(64)\n",
    "    m = data.reshape((8,8))\n",
    "    return m\n",
    "\n",
    "\n",
    "def data6():\n",
    "    df = pd.DataFrame({'x':[1,1,1,2,2,3,3,3], 'y':[1,2,3,1,2,1,2,3], 'v':[11,12,13,14,15,16,17,18]})\n",
    "    return df\n",
    "\n",
    "\n",
    "def data7():\n",
    "    data = (np.arange(16))**2/10 + 5\n",
    "    return data\n",
    "\n",
    "\n",
    "def data8():\n",
    "    df = pd.DataFrame({'x':[1,1,1,1,2,2,2,3,3,3,3,4,4,4,4], 'y':[1,2,3,4,1,2,3,1,2,3,4,1,2,3,4], 'v':[11,15,18,23,9,8,6,4,7,6,2,8,9,12,14]})\n",
    "    return df\n",
    "\n",
    "\n",
    "def data9():\n",
    "    df = pd.DataFrame({'x':[1,1,1,1,2,2,2,3,3,3,3,4,4,4,4],\n",
    "                       'y':[1,2,3,4,1,2,3,1,2,3,4,1,2,3,4],\n",
    "                       'v':[11.5,15.7,18.9,23.2,9.4,8.7,6.1,4.8,7.1,6.2,2.9,8.7,9.5,12.4,14.3]})\n",
    "    return df\n",
    "\n",
    "\n",
    "def data10():\n",
    "    df = pd.DataFrame({'x':[1,1,1,2,2,2,3,3],\n",
    "                       'y':[1,2,3,1,2,3,1,2],\n",
    "                       'v':[3.5, 5.5, 7.0, 3.0, 4.0, 2.0, 6, 5]})\n",
    "    return df\n",
    "\n",
    "\n",
    "def data11():\n",
    "    nx, ny, nz = 5, 4, 3\n",
    "    l = [(x,y,z) for z in range(nz) for y in range(ny) for x in range(nx)]\n",
    "    df = pd.DataFrame(l, columns=['x','y','z'])\n",
    "    df['v'] = df.index * 0.27\n",
    "    df2 = df.drop([18,20,59])\n",
    "    return df2\n",
    "\n",
    "\n",
    "def data12():\n",
    "    a=data11()\n",
    "    a=a[a.z==0]\n",
    "    a=a.drop(['z'],axis=1)\n",
    "    return a\n",
    "\n",
    "\n",
    "def data13():\n",
    "    df = pd.DataFrame({'x':[1,1,1,2,2,3,3,3], 'y':[1,2,3,1,2,1,2,3], 'v1':[3,4,3,3,5,4,3,5]})\n",
    "    return df\n",
    "\n",
    "\n",
    "def data14():\n",
    "    data = np.array([\n",
    "      1,1,1,\n",
    "      1,2,2,\n",
    "      1,1,1,\n",
    "\n",
    "      3,2,1,\n",
    "      1,1,1,\n",
    "      2,2,1,\n",
    "        \n",
    "      1,1,1,\n",
    "      1,3,1,\n",
    "      1,1,1\n",
    "    ])\n",
    "    m = data.reshape((3,3,3))\n",
    "    return m\n",
    "\n",
    "\n",
    "def test_datax():\n",
    "    assert data1().sum() == 320\n",
    "    assert data2().sum() == 138\n",
    "    assert data3().shape == (7,7)\n",
    "    assert np.sum(np.isnan(data3())) == 1\n",
    "    assert data5().sum() == 32.87392062325199\n",
    "    assert data6().x.sum() == 16\n",
    "    assert data7().sum() == 204\n",
    "    assert data8().v.sum() == 152\n",
    "    assert data9().sum().sum() == 233.4\n",
    "    assert data10().sum().sum() == 66\n",
    "    assert data11().sum().sum() == 705.71\n",
    "    assert 110.43 < data12().sum().sum() < 110.45\n",
    "    assert data13().sum().sum() == 61\n",
    "    assert data14().sum() == 36\n",
    "\n",
    "    \n",
    "test_datax()\n",
    "\n",
    "print('No error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# generate_ndarray\n",
    "# takes x,y,v DataFrame to generate numpy 2D array\n",
    "# takes x,y,z,v DataFrame to generate numpy 3D array\n",
    "#\n",
    "# Kenji Hirata, 1/1/2018\n",
    "# 8/31/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def generate_2darray(df):\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    m = np.empty((maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.y)- miny, int(a.x)- minx] = a.v\n",
    "    return m\n",
    "\n",
    "def generate_3darray(df):\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    minz = np.min(df.z)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    maxz = np.max(df.z)\n",
    "    m = np.empty((maxz - minz + 1, maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.z)- minz, int(a.y)- miny, int(a.x)- minx] = a.v\n",
    "    return m\n",
    "\n",
    "def generate_2darray_v1(df):\n",
    "    report('Generating 2-dimensional array')\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    m = np.empty((maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.y)- miny, int(a.x)- minx] = a.v1\n",
    "    return m\n",
    "\n",
    "def generate_3darray_v1(df):\n",
    "    report('Generating 3-dimensional array')\n",
    "    minx = np.min(df.x)\n",
    "    miny = np.min(df.y)\n",
    "    minz = np.min(df.z)\n",
    "    maxx = np.max(df.x)\n",
    "    maxy = np.max(df.y)\n",
    "    maxz = np.max(df.z)\n",
    "    m = np.empty((maxz - minz + 1, maxy - miny + 1, maxx - minx + 1))\n",
    "    m.fill(np.nan)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        a = df.iloc[i]\n",
    "        m[int(a.z)- minz, int(a.y)- miny, int(a.x)- minx] = a.v1\n",
    "    return m\n",
    "\n",
    "\n",
    "def test_generate_2darray():\n",
    "    a = generate_2darray(data6())\n",
    "    assert a.shape == (3,3)\n",
    "    assert np.isnan(a[2,1])\n",
    "    a[np.isnan(a)] = 0\n",
    "    assert np.sum(a) == 11+12+13+14+15+16+17+18\n",
    "\n",
    "def test_generate_3darray():\n",
    "    a = generate_3darray(data11())\n",
    "    assert a.shape == (3,4,5)\n",
    "    assert np.isnan(a[0,3,3])\n",
    "    assert np.isnan(a[1,0,0])\n",
    "    assert np.isnan(a[2,3,4])\n",
    "    a[np.isnan(a)] = 0\n",
    "    #print(np.sum(a))\n",
    "    assert 451.71 < np.sum(a) < 451.72\n",
    "\n",
    "def test_generate_2darray_v1():\n",
    "    a0 = data6()\n",
    "    a0['v1'] = a0.v % 3\n",
    "    a = generate_2darray_v1(a0)\n",
    "    assert a.shape == (3,3)\n",
    "    assert np.isnan(a[2,1])\n",
    "    a[np.isnan(a)] = 0\n",
    "    assert np.sum(a) == 2+1+2+1+2\n",
    "\n",
    "def test_generate_3darray_v1():\n",
    "    a0 = data11()\n",
    "    a0['v1'] = np.floor(a0.v / 3)\n",
    "    a = generate_3darray_v1(a0)\n",
    "    #print(a)\n",
    "    assert a.shape == (3,4,5)\n",
    "    assert np.isnan(a[0,3,3])\n",
    "    assert np.isnan(a[1,0,0])\n",
    "    assert np.isnan(a[2,3,4])\n",
    "    a[np.isnan(a)] = 0\n",
    "    #print(a.sum())\n",
    "    assert np.sum(a) == 123\n",
    "\n",
    "    \n",
    "\n",
    "test_generate_2darray()\n",
    "test_generate_3darray()\n",
    "test_generate_2darray_v1()\n",
    "test_generate_3darray_v1()\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# discritize\n",
    "# takes ndarray of continuous value, returns same size of ndarray of nbin levels decrete value.\n",
    "# The input ndarray may contain NaN.\n",
    "# The result type is 'ndarray of float' rather than int because NaN does not exist in int type.\n",
    "#\n",
    "# Kenji Hirata, 11/21/2017\n",
    "# modified on 12/04\n",
    "#\n",
    "################################################\n",
    "\n",
    "def discritize(data, nbin, lo, hi, getCategories = False):\n",
    "    '''If you want lo and hi to be min and max of the data, respectively,\n",
    "    give np.nan for both lo and hi.\n",
    "    '''\n",
    "    if np.isnan(lo):\n",
    "        lo = np.nanmin(data.ravel())\n",
    "    if np.isnan(hi):\n",
    "        hi = np.nanmax(data.ravel())\n",
    "    \n",
    "    if lo > hi:\n",
    "        raise ValueError('lo must not be higher than hi.')\n",
    "    \n",
    "    R = np.floor((nbin * (data - lo) / (hi-lo)))\n",
    "    R[R < 0] = 0\n",
    "    R[R >= nbin] = nbin -1\n",
    "\n",
    "    cats = np.array([(hi - lo) / nbin * i + lo for i in range(nbin+1)])\n",
    "    report(('bins', nbin))\n",
    "    report(('categories', cats))\n",
    "    \n",
    "    if getCategories:\n",
    "        return R, cats\n",
    "    else:\n",
    "        return R \n",
    "\n",
    "    \n",
    "def test_discritize():\n",
    "    a = np.arange(1,2,0.1)\n",
    "    #print(a)\n",
    "    a1, c1 = discritize(a,5,1,2,True)\n",
    "    #print(a1)\n",
    "    #print(c1)\n",
    "    #print(a1.sum())\n",
    "    assert a1.sum() == 20\n",
    "    assert c1.sum() == 9\n",
    "    a2 = discritize(a,10,0,3)\n",
    "    #print(a2)\n",
    "    #print(a2.sum())\n",
    "    assert a2.sum() == 45\n",
    "    a3 = discritize(a,10,1.3,1.7)\n",
    "    #print(a3)\n",
    "    #print(a3.sum())\n",
    "    assert a3.sum() == 41\n",
    "    df = data11()\n",
    "    #display(df)\n",
    "    df['v1'] = discritize(df.v, 8, 0, 20)\n",
    "    #display(df)\n",
    "    assert df.v1.sum() == 153\n",
    "    df['v1'] = discritize(df.v, 10, 5, 10)\n",
    "    #display(df)\n",
    "    assert df.v1.sum() == 276\n",
    "    df['v1'] = discritize(df.v, 8, np.nan, np.nan)\n",
    "    #print(df.v1.sum())\n",
    "    #display(df)\n",
    "    assert df.v1.sum() == 203\n",
    "\n",
    "test_discritize()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# complement_crosstab\n",
    "#\n",
    "# Kenji Hirata, 11/21/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def complement_crosstab2(cr, index_hi=np.nan, column_hi=np.nan):\n",
    "    if np.isnan(index_hi):\n",
    "        index_hi = int(np.max(cr.index.values)+1)\n",
    "    if np.isnan(column_hi):\n",
    "        column_hi = int(np.max(cr.columns.values)+1)\n",
    "    d = pd.DataFrame(np.zeros((index_hi, column_hi)), index=np.arange(index_hi), columns=np.arange(column_hi))\n",
    "    cr1 = cr.add(d, fill_value=0)\n",
    "    return cr1\n",
    "\n",
    "def test_complement_crosstab2():\n",
    "    t = pd.crosstab(np.array([1,1,1,2,5]),np.array([1,2,2,2,4]))\n",
    "    #display(t)\n",
    "    t1 = complement_crosstab2(t)\n",
    "    #display(t1)\n",
    "    assert t1.shape == (6,5)\n",
    "    assert np.allclose(t1.columns, pd.Index([0,1,2,3,4]))\n",
    "    assert np.allclose(t1.index, pd.Index([0,1,2,3,4,5]))\n",
    "    assert t1.iloc[1,2] == 2\n",
    "    assert t1.iloc[5,4] == 1\n",
    "    \n",
    "test_complement_crosstab2()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Usual parameters in Python\n",
    "# Kenji Hirata, 11/22/2017\n",
    "# 9/1/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def usualParams(v):\n",
    "    report('### Calculating usual parameters')\n",
    "    \n",
    "    SUVmax = max(v)\n",
    "    SUVmean = np.mean(v)\n",
    "    n = len(v) * 1*1*1\n",
    "    s = np.sum(v)\n",
    "    cols = ['SUVmax', 'SUVmean', 'NumOfVoxels', 'SUVsum']\n",
    "    vals = [[SUVmax, SUVmean, n, s]]\n",
    "    results = pd.DataFrame(data=vals, columns=cols)\n",
    "\n",
    "    report(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "def test_usualParams():\n",
    "    a = usualParams(data11().v)\n",
    "    #display(a)\n",
    "    assert a.SUVmax[0] == 15.66\n",
    "    assert 7.924736 < a.SUVmean[0] < 7.924738\n",
    "    assert a.NumOfVoxels[0] == 57\n",
    "    assert 451.70 < a.SUVsum[0] < 451.72\n",
    "    \n",
    "    \n",
    "test_usualParams()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Histogram parameters in Python\n",
    "# Kenji Hirata, 11/22/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def histParams(hist):\n",
    "    report('### Calculating histogram parameters')\n",
    "    \n",
    "    SDhist = np.std(hist, ddof=1)\n",
    "    \n",
    "    #Skewness = (1/N)*np.sum((h-np.mean(h))**3) / ((1/N)*np.sum((h-np.mean(h))**2))**(3/2)\n",
    "    Skewness = scipy.stats.skew(hist)\n",
    "    \n",
    "    #Kurtosis = (1/N)*np.sum((h-np.mean(h))**4) / ((1/N)*np.sum((h-np.mean(h))**2))**2 - 3\n",
    "    Kurtosis = scipy.stats.kurtosis(hist)\n",
    "    \n",
    "    tb = pd.crosstab(hist,0)\n",
    "    p = complement_crosstab2(tb).values.ravel()/len(hist)\n",
    "    #print('Probability of gray-level i', p)\n",
    "    EnergyHist = np.sum(p*p)\n",
    "    \n",
    "    p_nz = p[p != 0]\n",
    "    EntropyHist = -np.sum(p_nz*np.log(p_nz))\n",
    "    \n",
    "    cols = ['SDhist', 'Skewness', 'Kurtosis', 'EnergyHist', 'EntropyHist']\n",
    "    vals = [[SDhist, Skewness, Kurtosis, EnergyHist, EntropyHist]]\n",
    "    results = pd.DataFrame(data=vals, columns=cols)\n",
    "\n",
    "    report(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "def test_histParams():\n",
    "    v = data11().v\n",
    "    v1 = discritize(v, 8,0,20)\n",
    "    h = histParams(v1)\n",
    "    #display(h)\n",
    "    assert 1.872334 < h.SDhist[0] < 1.872336\n",
    "    assert 0.02134 < h.Skewness[0] < 0.02136\n",
    "    assert -1.175234 < h.Kurtosis[0] < -1.175232\n",
    "    assert 0.153585 < h.EnergyHist[0] < 0.153587\n",
    "    assert 1.899741 < h.EntropyHist[0] < 1.899743\n",
    "\n",
    "test_histParams()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Define 4 directions for 2-d\n",
    "#        13 directions for 3-d\n",
    "# In preparation for calculating GLCM and GLRLM\n",
    "#\n",
    "# Kenji Hirata, 1/2/2018\n",
    "# bug fixed 1/9/2018 (13 directions)\n",
    "#\n",
    "################################################\n",
    "\n",
    "def fourDirections():\n",
    "    a=[(i,j) for i in [-1,0,1] for j in [-1,0,1]]\n",
    "    a.remove((0,0))\n",
    "\n",
    "    for b in a:\n",
    "        _b = (-b[0],-b[1])\n",
    "        if _b in a:\n",
    "            a.remove(_b)\n",
    "    return a\n",
    "\n",
    "    \n",
    "def thirteenDirections():\n",
    "    a=[(i,j,k) for i in [-1,0,1] for j in [-1,0,1] for k in [-1,0,1]]\n",
    "    a.remove((0,0,0))\n",
    "\n",
    "    for b in a:\n",
    "        _b = (-b[0],-b[1],-b[2])\n",
    "        if _b in a:\n",
    "            a.remove(_b)\n",
    "    return a\n",
    "\n",
    "\n",
    "def test_fourDirections():\n",
    "    a = fourDirections()\n",
    "    #print(a)\n",
    "    b = [(0,1), (1,0), (1,1), (1,-1)]\n",
    "    for f in a:\n",
    "        _f = (-f[0],-f[1])\n",
    "        assert (f in b) or (_f in b)\n",
    "    for f in b:\n",
    "        _f = (-f[0],-f[1])\n",
    "        assert (f in a) or (_f in a)\n",
    "    \n",
    "def test_thirteenDirections():\n",
    "    a = thirteenDirections()\n",
    "    #print(a)\n",
    "    b = [(0,0,1), (0,1,1), (0,1,0), (0,1,-1),\n",
    "         (1,0,0), (1,0,1), (1,1,1), (1,1,0),\n",
    "         (1,1,-1), (1,0,-1),(1,-1,-1),(1,-1,0),(1,-1,1)]\n",
    "    for f in a:\n",
    "        _f = (-f[0],-f[1],-f[2])\n",
    "        assert (f in b) or (_f in b)\n",
    "    for f in b:\n",
    "        _f = (-f[0],-f[1],-f[2])\n",
    "        assert (f in a) or (_f in a)\n",
    "\n",
    "    # The total of 13 directions mean as follows:\n",
    "    #\n",
    "    # (0,0,1)  3 o'clock\n",
    "    # (0,1,1)　4:30 o'clock\n",
    "    # (0,1,0)　6 o'clock\n",
    "    # (0,1,-1) 7:30 o'clock\n",
    "    #  9  o'clock and later are omitted because it already appreared.\n",
    "    # \n",
    "    #  Downward direction (delta z=1)\n",
    "    # (1,0,0) center of the clock\n",
    "    # (1,0,1) 3 o'clock\n",
    "    # (1,1,1) 4:30 o'clock\n",
    "    # (1,1,0) 6 o'clock\n",
    "    # (1,1,-1) 7.5 o'clock\n",
    "    # (1,0,-1) 9 o'clock\n",
    "    # (1,-1,-1) 10:30 o'clock\n",
    "    # (1,-1,0) 12 o'clock\n",
    "    # (1,-1,1) 1:30 o'clock\n",
    "\n",
    "\n",
    "test_fourDirections()\n",
    "test_thirteenDirections()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Generate gray-level co-occurrence matrix (GLCM) based texture parameters in Python\n",
    "# Kenji Hirata, 1/2/2018\n",
    "# bug fixed 9/2/2018 in comat2d()\n",
    "#\n",
    "################################################\n",
    "\n",
    "def comat2d(d, offset, nbin):\n",
    "    d1 = pd.DataFrame({'v2': d.v1, 'y': d.y - offset[0],  'x': d.x - offset[1]})\n",
    "    d2 = pd.merge(d,d1)\n",
    "    cr = pd.crosstab(d2.v1, d2.v2)\n",
    "    cr1 = complement_crosstab2(cr, nbin, nbin)\n",
    "    return cr1, d2\n",
    "\n",
    "def comat3d(d, offset, nbin):\n",
    "    d1 = pd.DataFrame({'v2': d.v1, 'z': d.z - offset[0], 'y': d.y - offset[1], 'x': d.x - offset[2]})\n",
    "    # subtracting offset may look tricky; with this operation current(v1) and (current + offset)(v2) are paired.\n",
    "    d2 = pd.merge(d,d1)\n",
    "    cr = pd.crosstab(d2.v1, d2.v2)\n",
    "    cr1 = complement_crosstab2(cr, nbin, nbin)\n",
    "    return cr1, d2\n",
    "\n",
    "\n",
    "def test_comat2d():\n",
    "    df = data13()\n",
    "    #display(df)\n",
    "    sum = np.zeros((10,10))\n",
    "    for dir in fourDirections():\n",
    "        com, df2 = comat2d(df, dir , 10)\n",
    "        #print(dir)\n",
    "        #display(df2)\n",
    "        #display(com)\n",
    "        sum += com\n",
    "    #print(sum)\n",
    "    answer = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 2, 2, 2, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 3, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 3, 2, 1, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,]]\n",
    "    assert np.allclose(sum, answer)\n",
    "\n",
    "    \n",
    "def test_comat3d():\n",
    "    df = data11()\n",
    "    df['v1'] = discritize(df.v, 8, 0, 20)\n",
    "    #display(df)\n",
    "    sum = np.zeros((8,8))\n",
    "    for dir in thirteenDirections():\n",
    "        com, df2 = comat3d(df, dir , 8)\n",
    "        #print(dir)\n",
    "        #display(df2)\n",
    "        #display(com)\n",
    "        sum += com\n",
    "    #print(sum)\n",
    "    answer = [[21,  0,  0,  0,  0,  0,  0,  0,],\n",
    "              [13, 14,  0,  0,  0,  0,  0,  0,],\n",
    "              [38, 10, 11,  0,  0,  0,  0,  0,],\n",
    "              [23, 41, 16, 20,  0,  0,  0,  0,],\n",
    "              [ 0,  6, 29, 16, 11,  0,  0,  0,],\n",
    "              [ 0,  0, 19, 43, 19, 16,  0,  0,],\n",
    "              [ 0,  0,  0, 15,  3, 10,  2,  0,],\n",
    "              [ 0,  0,  0,  0,  0,  0,  0,  0,]]\n",
    "    assert np.allclose(sum, answer)\n",
    "    \n",
    "\n",
    "test_comat2d()\n",
    "test_comat3d()\n",
    "\n",
    "print('No error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Calculate texture features from GLCM\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def comatParams2d(d, nbin):\n",
    "    offsets = fourDirections()\n",
    "    return _comatParams(d,nbin,offsets)\n",
    "    \n",
    "def comatParams3d(d, nbin):\n",
    "    offsets = thirteenDirections()\n",
    "    return _comatParams(d,nbin,offsets)\n",
    "\n",
    "def _comatParams(d, nbin, offsets):\n",
    "    report('### Generating Co-occurence matrix')\n",
    "\n",
    "    dim = len(offsets[0])\n",
    "    seq = np.arange(nbin)\n",
    "    ii = np.tile(seq, (nbin,1))\n",
    "    jj = ii.T\n",
    "    lst =[]\n",
    "\n",
    "    for o in offsets:\n",
    "\n",
    "        if dim==2:\n",
    "            com, d2 = comat2d(d, o, nbin)\n",
    "        elif dim==3:\n",
    "            com, d2 = comat3d(d, o, nbin)\n",
    "        \n",
    "        report(('offset', o))\n",
    "        report(com)\n",
    "        cm = com.values\n",
    "        \n",
    "        cm = cm / np.sum(cm)\n",
    "        cm_nz = cm[cm != 0]\n",
    "        \n",
    "        homogeneity = np.sum(cm / (1+np.abs(ii-jj)))\n",
    "        energy = np.sum(cm**2)\n",
    "        correlation = np.corrcoef(d2.v1, d2.v2)[0,1]\n",
    "        \n",
    "        contrast = np.sum((ii-jj)**2*cm)\n",
    "        entropy = -np.sum(cm_nz * np.log(cm_nz))\n",
    "        dissimilarity = np.sum(np.abs(ii-jj)*cm)\n",
    "\n",
    "        ids = ['HomogeneityGLCM','EnergyGLCM','CorrelationGLCM','ContrastGLCM','EntropyGLCM','DissimilarityGLCM']\n",
    "        se=pd.Series([homogeneity, energy, correlation, contrast, entropy, dissimilarity], ids)\n",
    "        \n",
    "        if dim==2:\n",
    "            se.name = str(o[0])+'_'+str(o[1])\n",
    "        elif dim==3:\n",
    "            se.name = str(o[0])+'_'+str(o[1])+'_'+str(o[2])\n",
    "\n",
    "        lst.append(se)\n",
    "        \n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    report(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def test_comatParams2d():\n",
    "    df = data13()\n",
    "    results = comatParams2d(df, 8)\n",
    "    #display(results)\n",
    "    assert np.allclose(results.loc['mean'],\n",
    "                       [0.559722, 0.319167, -0.250945, 1.758333, 1.159610, 1.100000])\n",
    "    \n",
    "    \n",
    "def test_comatParams3d():\n",
    "    df = data11()\n",
    "    df['v1'] = discritize(df.v, 8, 0, 20)\n",
    "    results = comatParams3d(df, 8)\n",
    "    #display(results)\n",
    "    assert np.allclose(results.loc['mean'],\n",
    "                       [0.474600, 0.148728, 0.948662, 3.592544, 2.019743, 1.615889])\n",
    "\n",
    "    \n",
    "test_comatParams2d()\n",
    "test_comatParams3d()\n",
    "\n",
    "    \n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Define xline, yline for 2d and xplain, yplain, zplain for 3d\n",
    "# in preparation of gray-level run-length matrix\n",
    "# Kenji Hirata, 11/23/2017\n",
    "# bug fixed 1/9/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def xline(x, m):\n",
    "    ny,nx = m.shape\n",
    "    return [(y,x) for y in range(ny)]\n",
    "\n",
    "def yline(y, m):\n",
    "    ny,nx = m.shape\n",
    "    return [(y,x) for x in range(nx)]\n",
    "\n",
    "def xplain(x, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for z in range(nz) for y in range(ny)]\n",
    "\n",
    "def yplain(y, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for z in range(nz) for x in range(nx)]\n",
    "\n",
    "def zplain(z, m):\n",
    "    nz,ny,nx = m.shape\n",
    "    return [(z,y,x) for y in range(ny) for x in range(nx)]\n",
    "\n",
    "\n",
    "def test_xline():\n",
    "    d = np.zeros((3,4))\n",
    "    #print(d)\n",
    "    sum = 0\n",
    "    for i in range(d.shape[1]):\n",
    "        lines = xline(i, d)\n",
    "        assert len(lines) == 3\n",
    "        #print(i, lines)\n",
    "        sum += np.sum(lines)\n",
    "    assert sum == 30\n",
    "\n",
    "\n",
    "def test_yline():\n",
    "    d = np.zeros((3,4))\n",
    "    #print(d)\n",
    "    sum = 0\n",
    "    for i in range(d.shape[1]):\n",
    "        lines = yline(i, d)\n",
    "        assert len(lines) == 4\n",
    "        #print(i, lines)\n",
    "        sum += np.sum(lines)\n",
    "    assert sum == 48\n",
    "    \n",
    "    \n",
    "def test_xplain():\n",
    "    d = np.zeros((3,4,5))\n",
    "    #print(d)\n",
    "    sum = 0\n",
    "    for i in range(d.shape[1]):\n",
    "        lines = xplain(i, d)\n",
    "        assert len(lines) == d.shape[0] * d.shape[1]\n",
    "        #print(i, lines)\n",
    "        sum += np.sum(lines)\n",
    "    #print(sum)\n",
    "    assert sum == 192\n",
    "\n",
    "    \n",
    "def test_yplain():\n",
    "    d = np.zeros((3,4,5))\n",
    "    #print(d)\n",
    "    sum = 0\n",
    "    for i in range(d.shape[1]):\n",
    "        lines = yplain(i, d)\n",
    "        assert len(lines) == d.shape[0] * d.shape[2]\n",
    "        #print(i, lines)\n",
    "        sum += np.sum(lines)\n",
    "    #print(sum)\n",
    "    assert sum == 270\n",
    "    \n",
    "    \n",
    "def test_zplain():\n",
    "    d = np.zeros((3,4,5))\n",
    "    #print(d)\n",
    "    sum = 0\n",
    "    for i in range(d.shape[1]):\n",
    "        lines = zplain(i, d)\n",
    "        assert len(lines) == d.shape[1] * d.shape[2]\n",
    "        #print(i, lines)\n",
    "        sum += np.sum(lines)\n",
    "    #print(sum)\n",
    "    assert sum == 400\n",
    "    \n",
    "\n",
    "test_xline()\n",
    "test_yline()\n",
    "test_xplain()\n",
    "test_yplain()\n",
    "test_zplain()\n",
    "    \n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Run length encoding (RLE) for gray-level run-length matrix\n",
    "# Kenji Hirata, 11/23/2017\n",
    "# bug fixed 1/9/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "def rle(vec):\n",
    "    if len(vec)==0:\n",
    "        return [],[]\n",
    "    if len(vec)==1:\n",
    "        return vec,[1]\n",
    "    \n",
    "    prev = vec[0]\n",
    "    count = 1\n",
    "    vallst = []\n",
    "    lenlst = []\n",
    "    for a in vec[1:]:\n",
    "        if (a == prev) or (np.isnan(a) and np.isnan(prev)):\n",
    "            count += 1\n",
    "        else:\n",
    "            vallst.append(prev)\n",
    "            lenlst.append(count)\n",
    "            count = 1\n",
    "            prev = a\n",
    "    else:\n",
    "        vallst.append(a)\n",
    "        lenlst.append(count)\n",
    "    return vallst,lenlst\n",
    "\n",
    "\n",
    "def test_rle():\n",
    "    v = [1,1,4,6,6,np.nan,2,2,2,2,3,1,3,np.nan,np.nan,1,1,np.nan]\n",
    "    vals,lens = rle(v)\n",
    "    #print(v)\n",
    "    #print(vals)\n",
    "    #print(lens)\n",
    "    a = []\n",
    "    for x in zip(vals, lens):\n",
    "        a = a + [x[0]]*x[1]\n",
    "    #print(a)\n",
    "    assert np.allclose(v,a, equal_nan=True)\n",
    "    \n",
    "test_rle()\n",
    "\n",
    "print('No error.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Generate gray-level run-length matrix (GLRLM)\n",
    "# Kenji Hirata, 11/23/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def getGlrlm2d(discritizedArray, initialpoints, dy, dx):\n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    a1d =[]\n",
    "    for current in initialpoints:\n",
    "        cy,cx = current\n",
    "        while((cy >= 0) and (cx >= 0) and (cy < ny) and (cx < nx)):\n",
    "            a1d.append(m[cy,cx])\n",
    "            cx += dx\n",
    "            cy += dy\n",
    "        a1d.append(np.nan)\n",
    "    vals, lens = rle(a1d)\n",
    "    \n",
    "    flag = ~np.isnan(vals)\n",
    "    vals1 = np.array(vals)[flag].astype(int)\n",
    "    lens1 = np.array(lens)[flag]\n",
    "    cr = pd.crosstab(vals1,lens1)\n",
    "    cr1 = complement_crosstab2(cr)\n",
    "    return cr1\n",
    "\n",
    "def getGlrlm3d(discritizedArray, initialpoints, dz, dy, dx):\n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    a1d =[]\n",
    "    for current in initialpoints:\n",
    "        cz,cy,cx = current\n",
    "        while((cz >= 0) and (cy >= 0) and (cx >= 0) and (cz < nz) and (cy < ny) and (cx < nx)):\n",
    "            a1d.append(m[cz,cy,cx])\n",
    "            cx += dx\n",
    "            cy += dy\n",
    "            cz += dz\n",
    "        a1d.append(np.nan)\n",
    "    vals, lens = rle(a1d)\n",
    "    #print(a1d)\n",
    "    #print(vals)\n",
    "    #print(lens)\n",
    "    \n",
    "    flag = ~np.isnan(vals)\n",
    "    vals1 = np.array(vals)[flag].astype(int)\n",
    "    lens1 = np.array(lens)[flag]\n",
    "    cr = pd.crosstab(vals1,lens1)\n",
    "    cr1 = complement_crosstab2(cr)\n",
    "    return cr1\n",
    "\n",
    "\n",
    "def test_getGlrlm2d():\n",
    "    m = np.array(data2(), dtype = np.float)\n",
    "    m[1,2:4]=np.nan\n",
    "    m[2,3]=np.nan\n",
    "    m[3,2]=3\n",
    "    #print(m)\n",
    "    pt = xline(0,m)\n",
    "    g = getGlrlm2d(m,pt,0,1)\n",
    "    #display(g)\n",
    "    answer = [[0, 0, 0, 0],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 0, 0, 0],\n",
    "              [0, 3, 3, 1],\n",
    "              [0, 2, 4, 0],\n",
    "              [0, 4, 1, 0],\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 2, 0, 0]]\n",
    "    assert np.allclose(g.values, answer)\n",
    "\n",
    "    pt = set(xline(0, m)) | set(yline(m.shape[0]-1, m))\n",
    "    g = getGlrlm2d(m,pt,-1,1)\n",
    "    #display(g)\n",
    "    answer = [[0, 0, 0],\n",
    "              [0, 1, 0],\n",
    "              [0, 0, 0],\n",
    "              [0, 4, 4],\n",
    "              [0, 6, 2],\n",
    "              [0, 4, 1],\n",
    "              [0, 1, 0],\n",
    "              [0, 2, 0]]\n",
    "    assert np.allclose(g.values, answer)\n",
    "\n",
    "    \n",
    "def test_getGlrlm3d():\n",
    "    df = data11()\n",
    "    df['v1'] = discritize(df.v, 8, 0, 20)\n",
    "    m = generate_3darray_v1(df)\n",
    "    #print(m)\n",
    "    pt = xplain(0,m)\n",
    "    g = getGlrlm3d(m, pt, 0,0,1 )\n",
    "    #display(g)\n",
    "    answer = [[0, 0, 0, 0, 0, 2,],\n",
    "              [0, 0, 0, 1, 0, 1,],\n",
    "              [0, 1, 0, 1, 1, 0,],\n",
    "              [0, 0, 1, 1, 0, 1,],\n",
    "              [0, 0, 2, 0, 0, 1,],\n",
    "              [0, 1, 0, 1, 0, 1,],\n",
    "              [0, 0, 0, 1, 0, 0,]]\n",
    "    assert np.allclose(g.values, answer)\n",
    "\n",
    "    m[0,1,1]=6\n",
    "    m[1,2,2]=6\n",
    "    #print(m)\n",
    "    pt = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(0,m))\n",
    "    g = getGlrlm3d(m, pt, 1,1,1 )\n",
    "    #display(g)\n",
    "    answer = [[0, 9, 0, 0],\n",
    "              [0, 8, 0, 0],\n",
    "              [0, 8, 0, 0],\n",
    "              [0, 9, 0, 0],\n",
    "              [0, 9, 0, 0],\n",
    "              [0, 9, 0, 0],\n",
    "              [0, 2, 0, 1]]\n",
    "    assert np.allclose(g.values, answer)\n",
    "\n",
    "    m = data14()\n",
    "    #print(m)\n",
    "    xp = xplain(0,m)\n",
    "    for p in xp:\n",
    "        m[p] = -1\n",
    "    #print(m)\n",
    "    \n",
    "    m = data14()\n",
    "    yp = yplain(2,m)\n",
    "    for p in yp:\n",
    "        m[p] = -1\n",
    "    #print(m)\n",
    "\n",
    "    m = data14()\n",
    "    zp = zplain(2,m)\n",
    "    for p in zp:\n",
    "        m[p] = -1\n",
    "    #print(m)\n",
    "\n",
    "    m = data14()\n",
    "    pt = set(xp) | set(yp) | set(zp)\n",
    "    for p in pt:\n",
    "        m[p] = -1\n",
    "    \n",
    "    answer = [[[-1,  1,  1],\n",
    "               [-1,  2,  2],\n",
    "               [-1, -1, -1]],\n",
    "              \n",
    "              [[-1,  2,  1],\n",
    "               [-1,  1,  1],\n",
    "               [-1, -1, -1]],\n",
    "              \n",
    "              [[-1, -1, -1],\n",
    "               [-1, -1, -1],\n",
    "               [-1, -1, -1]]]\n",
    "    assert np.allclose(m, answer)\n",
    "        \n",
    "    #print(m)\n",
    "    #print(pt)\n",
    "\n",
    "    m = data14()\n",
    "    g = getGlrlm3d(m, pt, -1,-1,1 )\n",
    "    #display(g)\n",
    "    answer = [[0, 0, 0, 0],\n",
    "              [0,13, 2, 1],\n",
    "              [0, 1, 2, 0],\n",
    "              [0, 2, 0, 0]]\n",
    "    assert np.allclose(g.values, answer)\n",
    "\n",
    "\n",
    "test_getGlrlm2d()\n",
    "test_getGlrlm3d()\n",
    "\n",
    "print('No error.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Calculate features from GLRLM or GLZSM\n",
    "# Kenji Hirata, 11/23/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def calcGlrlmParams(glrlm_or_glszm, mode):\n",
    "    '''mode is either 'R' or 'Z'\n",
    "    'R' indicates GLRLM, and 'Z' indicates GLZSM.\n",
    "    The calculation formulas are completely same between 'R' and 'Z';\n",
    "    the only difference is variable name (i.e., index of the returning pd.Series)\n",
    "    '''\n",
    "    \n",
    "    # left-most column indicating number of run(size)=0 must be removed because it is unnecessary and even causes an adverse effect of divided-by-zero error.\n",
    "    mat = glrlm_or_glszm.values[:,1:]\n",
    "\n",
    "    sh = mat.shape\n",
    "    jj = np.tile(np.arange(sh[1])+1, (sh[0],1))\n",
    "    ii = np.tile(np.arange(sh[0])+1, (sh[1],1)).T\n",
    "    \n",
    "    SRE   = (1/np.sum(mat)) * np.sum(mat/jj**2)\n",
    "    LRE   = (1/np.sum(mat)) * np.sum(mat*jj**2)\n",
    "    LGRE  = (1/np.sum(mat)) * np.sum(mat/ii**2)\n",
    "    HGRE  = (1/np.sum(mat)) * np.sum(mat*ii**2)\n",
    "    SRLGE = (1/np.sum(mat)) * np.sum(mat/ii**2/jj**2)\n",
    "    SRHGE = (1/np.sum(mat)) * np.sum(mat*ii**2/jj**2)\n",
    "    LRLGE = (1/np.sum(mat)) * np.sum(mat/ii**2*jj**2)\n",
    "    LRHGE = (1/np.sum(mat)) * np.sum(mat*ii**2*jj**2)\n",
    "    GLNUr = (1/np.sum(mat)) * np.sum(np.sum(mat, axis=1)**2)\n",
    "    RLNU  = (1/np.sum(mat)) * np.sum(np.sum(mat, axis=0)**2)\n",
    "    RP    = np.sum(mat) / np.sum(jj * mat)\n",
    "\n",
    "    if mode == 'R':\n",
    "        ids = ['SRE', 'LRE', 'LGRE', 'HGRE', 'SRLGE', 'SRHGE', 'LRLGE', 'LRHGE', 'GLNUr', 'RLNU', 'RP']\n",
    "    if mode == 'Z':\n",
    "        ids = ['SZE', 'LZE', 'LGZE', 'HGZE', 'SZLGE', 'SZHGE', 'LZLGE', 'LZHGE', 'GLNUz', 'ZLNU', 'ZP']\n",
    "\n",
    "    se = pd.Series([SRE, LRE, LGRE, HGRE, SRLGE, SRHGE, LRLGE, LRHGE, GLNUr, RLNU, RP], ids)\n",
    "    return se\n",
    "\n",
    "\n",
    "\n",
    "def test_calcGlrlmParams():\n",
    "    df = data11()\n",
    "    df['v1'] = discritize(df.v, 8, 0, 20)\n",
    "    m = generate_3darray_v1(df)\n",
    "    #print(m)\n",
    "    pt = xplain(0,m)\n",
    "    g = getGlrlm3d(m, pt, 0,0,1 )\n",
    "    r = calcGlrlmParams(g, 'R')\n",
    "    #print(r)\n",
    "    assert 0.212238 < r['SRE'] < 0.212240\n",
    "    assert 13.235293 < r['LRE'] < 13.235295\n",
    "    assert 0.190856 < r['LGRE'] < 0.190858\n",
    "    assert 18.647058 < r['HGRE'] < 18.647060\n",
    "    assert 0.019357 < r['SRLGE'] < 0.019359\n",
    "    assert 4.591126 < r['SRHGE'] < 4.591128\n",
    "    assert 3.896457 < r['LRLGE'] < 3.896459\n",
    "    assert 209.058823 < r['LRHGE'] < 209.058825\n",
    "    assert 2.647058 < r['GLNUr'] < 2.647060\n",
    "    assert 4.411764 < r['RLNU'] < 4.411766\n",
    "    assert 0.298245 < r['RP'] < 0.298246\n",
    "    \n",
    "test_calcGlrlmParams()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eff559206c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[1;31m#test_combineGlrlm2d_retired()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m \u001b[0mtest_combineGlrlm2d_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[1;31m#test_combineGlrlm3d_retired()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0mtest_combineGlrlm3d_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-eff559206c05>\u001b[0m in \u001b[0;36mtest_combineGlrlm2d_new\u001b[0;34m()\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[1;32massert\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[1;31m#実際のfeature値を比較しておくこと\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#\n",
    "# Combine features from GLRLM or GLZSM\n",
    "# Kenji Hirata, 11/23/2017\n",
    "#\n",
    "################################################\n",
    "        \n",
    "def combineGlrlm2d_retired(discritizedArray, test_mode = False):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    lst = []\n",
    "    test_points = []\n",
    "\n",
    "    def sub(m, points, dy, dx):\n",
    "        g = getGlrlm2d(m, points, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str(dy)+'_'+str(dx)\n",
    "        lst.append(se)\n",
    "        ## test purpose\n",
    "        nonlocal test_points\n",
    "        if test_mode:\n",
    "            test_points += [(points,(dy,dx),g)]\n",
    "    \n",
    "    points = xline(0, m)\n",
    "    sub(m, points, 0, 1)\n",
    "\n",
    "    points = yline(0, m)\n",
    "    sub(m, points, 1, 0)\n",
    "\n",
    "    points = set(xline(0, m)) | set(yline(0, m))\n",
    "    sub(m, points, 1, 1)\n",
    "\n",
    "    points = set(xline(0, m)) | set(yline(nx-1, m))\n",
    "    sub(m, points, -1, 1)\n",
    "    \n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    report(df)\n",
    "    \n",
    "    if test_mode:\n",
    "        return df, test_points\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    \n",
    "def combineGlrlm2d_new(discritizedArray, test_mode = False):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    lst = []\n",
    "    test_points = []\n",
    "\n",
    "    def sub(m, dy, dx):\n",
    "        points = []\n",
    "        if (dx == 1):\n",
    "            points += xline(0, m)\n",
    "        if (dx == -1):\n",
    "            points += xline(nx-1, m)\n",
    "        if (dy == 1):\n",
    "            points += yline(0, m)\n",
    "        if (dy == -1):\n",
    "            points += yline(ny-1, m)\n",
    "        points = set(points)\n",
    "        \n",
    "        g = getGlrlm2d(m, points, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str(dy)+'_'+str(dx)\n",
    "        lst.append(se)\n",
    "        ## test purpose\n",
    "        nonlocal test_points\n",
    "        if test_mode:\n",
    "            test_points += [(points,(dy,dx),g)]\n",
    "    \n",
    "    \n",
    "    for dy,dx in fourDirections():\n",
    "        sub(m, dy, dx)\n",
    "    \n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "    report(df)\n",
    "    \n",
    "    if test_mode:\n",
    "        return df, test_points\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def combineGlrlm3d_retired(discritizedArray, test_mode = False):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    lst =[]\n",
    "    test_points = []\n",
    "    \n",
    "    def sub(m, points, dz, dy, dx):\n",
    "        g = getGlrlm3d(m, points, dz, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str(dz)+'_'+str(dy)+'_'+str(dx)\n",
    "        lst.append(se)\n",
    "        ## test purpose\n",
    "        nonlocal test_points\n",
    "        if test_mode:\n",
    "            test_points += [(points,(dz,dy,dx),g)]\n",
    "\n",
    "        \n",
    "    ###\n",
    "    points = xplain(0, m)\n",
    "    sub(m, points, 0, 0, 1)\n",
    "    \n",
    "    points = yplain(0, m)\n",
    "    sub(m, points, 0, 1, 0)\n",
    "    \n",
    "    points = zplain(0, m)\n",
    "    sub(m, points, 1, 0, 0)\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m))\n",
    "    sub(m, points, 0, 1, 1)\n",
    "\n",
    "    points = set(yplain(0, m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, 1, 0)\n",
    "\n",
    "    points = set(zplain(0, m)) | set(xplain(0,m))\n",
    "    sub(m, points, 1, 0, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(ny-1,m))\n",
    "    sub(m, points, 0, -1, 1)\n",
    "\n",
    "    points = set(yplain(0, m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, 1, 0)\n",
    "\n",
    "    points = set(zplain(0, m)) | set(xplain(nx-1,m))\n",
    "    sub(m, points, 1, 0, -1)\n",
    "    ###\n",
    "\n",
    "    ###\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, 1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(0,m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, 1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(ny-1,m)) | set(zplain(0,m))\n",
    "    sub(m, points, 1, -1, 1)\n",
    "\n",
    "    points = set(xplain(0, m)) | set(yplain(ny-1,m)) | set(zplain(nz-1,m))\n",
    "    sub(m, points, -1, -1, 1)\n",
    "    ###\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "\n",
    "    if test_mode:\n",
    "        return df, test_points\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "def combineGlrlm3d_new(discritizedArray, test_mode = False):\n",
    "    \n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    lst =[]\n",
    "    test_points = []\n",
    "    \n",
    "    def sub(m, dz, dy, dx):\n",
    "        points = []\n",
    "        if (dx == 1):\n",
    "            points += xplain(0, m)\n",
    "        if (dx == -1):\n",
    "            points += xplain(nx-1, m)\n",
    "        if (dy == 1):\n",
    "            points += yplain(0, m)\n",
    "        if (dy == -1):\n",
    "            points += yplain(ny-1, m)\n",
    "        if (dz == 1):\n",
    "            points += zplain(0, m)\n",
    "        if (dz == -1):\n",
    "            points += zplain(ny-1, m)\n",
    "        points = set(points)\n",
    "        \n",
    "        g = getGlrlm3d(m, points, dz, dy, dx)\n",
    "        report(g)\n",
    "        se = calcGlrlmParams(g, 'R')\n",
    "        se.name = str(dz)+'_'+str(dy)+'_'+str(dx)\n",
    "        lst.append(se)\n",
    "        ## test purpose\n",
    "        nonlocal test_points\n",
    "        if test_mode:\n",
    "            test_points += [(points,(dz,dy,dx),g)]\n",
    "    \n",
    "    for dz,dy,dx in thirteenDirections():\n",
    "        sub(m, dz, dy, dx)\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    ave = df.mean()\n",
    "    ave.name = 'mean'\n",
    "    df = df.append(ave)\n",
    "\n",
    "    if test_mode:\n",
    "        return df, test_points\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "def combineGlrlm(discritizedArray):\n",
    "    \n",
    "    report('### Generating GLRLM')\n",
    "    \n",
    "    if len(discritizedArray.shape) == 2:\n",
    "        df = combineGlrlm2d_new(discritizedArray)\n",
    "    elif len(discritizedArray.shape) == 3:\n",
    "        df = combineGlrlm3d_new(discritizedArray)\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "    report(df)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def test_combineGlrlm2d_retired():\n",
    "    m0 = np.array([[1,2,3],[1,1,2],[1,1,1]]).reshape(3,3)\n",
    "    #print(m0)\n",
    "    m = np.copy(m0)\n",
    "    df, pt = combineGlrlm2d_retired(m, test_mode = True)\n",
    "    #print(pt)\n",
    "    assert len(pt) == 4\n",
    "    for pt1,dydx,g in pt:\n",
    "        m = np.copy(m0)\n",
    "        for pt2 in pt1:\n",
    "            m[pt2]=-1\n",
    "        #print(dydx)\n",
    "        #print(m)\n",
    "        #print(g)\n",
    "        g1 = np.sum(g, axis=0)\n",
    "        #print(np.inner(g1.index ,g1))\n",
    "        assert np.inner(g1.index ,g1) == m.size\n",
    "    \n",
    "    \n",
    "def test_combineGlrlm2d_new():\n",
    "    m0 = np.array([[1,2,3],[1,1,2],[1,1,1]]).reshape(3,3)\n",
    "    #print(m0)\n",
    "    m = np.copy(m0)\n",
    "    df, pt = combineGlrlm2d_new(m, test_mode = True)\n",
    "    #print(pt)\n",
    "    assert len(pt) == 4\n",
    "    for pt1,dydx,g in pt:\n",
    "        m = np.copy(m0)\n",
    "        for pt2 in pt1:\n",
    "            m[pt2]=-1\n",
    "        #print(dydx)\n",
    "        #print(m)\n",
    "        #print(g)\n",
    "        g1 = np.sum(g, axis=0)\n",
    "        #print(np.inner(g1.index ,g1))\n",
    "        assert np.inner(g1.index ,g1) == m.size\n",
    "    \n",
    "    assert 1==2\n",
    "    #実際のfeature値を比較しておくこと\n",
    "\n",
    "    \n",
    "    \n",
    "def test_combineGlrlm3d_retired():\n",
    "    m0 = np.array([[[1,1,2],[1,1,1]],[[1,2,2],[1,1,2]]]).reshape(2,2,3)\n",
    "    #print(m0)\n",
    "    m = np.copy(m0)\n",
    "    df, pt = combineGlrlm3d_retired(m, test_mode = True)\n",
    "    #print(pt)\n",
    "    assert len(pt) == 13\n",
    "    for pt1,dzdydx,g in pt:\n",
    "        m = np.copy(m0)\n",
    "        for pt2 in pt1:\n",
    "            m[pt2]=-1\n",
    "        #print()\n",
    "        #print(dzdydx)\n",
    "        #print(m)\n",
    "        #print(g)\n",
    "        g1 = np.sum(g, axis=0)\n",
    "        #print(np.inner(g1.index ,g1))\n",
    "        assert np.inner(g1.index ,g1) == m.size\n",
    "    \n",
    "def test_combineGlrlm3d_new():\n",
    "    m0 = np.array([[[1,1,2],[1,1,1]],[[1,2,2],[1,1,2]]]).reshape(2,2,3)\n",
    "    #print(m0)\n",
    "    m = np.copy(m0)\n",
    "    df, pt = combineGlrlm3d_new(m, test_mode = True)\n",
    "    #print(pt)\n",
    "    assert len(pt) == 13\n",
    "    for pt1,dzdydx,g in pt:\n",
    "        m = np.copy(m0)\n",
    "        for pt2 in pt1:\n",
    "            m[pt2]=-1\n",
    "        #print()\n",
    "        #print(dzdydx)\n",
    "        #print(m)\n",
    "        #print(g)\n",
    "        g1 = np.sum(g, axis=0)\n",
    "        #print(np.inner(g1.index ,g1))\n",
    "        assert np.inner(g1.index ,g1) == m.size\n",
    "    assert 1==2\n",
    "    #実際のfeature値を比較しておくこと\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_combineGlrlm():\n",
    "    m = np.random.randint(10,20,49).reshape(7,7)\n",
    "    #m = np.random.uniform(.zeros((2,2))\n",
    "    a = combineGlrlm(m)\n",
    "    b = combineGlrlm2d_new(m)\n",
    "    assert np.allclose(a,b)\n",
    "\n",
    "    m = np.random.randint(10,20,7**3).reshape(7,7,7)\n",
    "    #m = np.zeros((2,2,2))\n",
    "    a = combineGlrlm(m)\n",
    "    b = combineGlrlm3d_new(m)\n",
    "    assert np.allclose(a,b)\n",
    "    # これでOK\n",
    "    \n",
    "    \n",
    "#test_combineGlrlm2d_retired()\n",
    "test_combineGlrlm2d_new()\n",
    "#test_combineGlrlm3d_retired()\n",
    "test_combineGlrlm3d_new()\n",
    "test_combineGlrlm()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# gray-level zone-size matrix in Python\n",
    "# Kenji Hirata, 11/24/2017\n",
    "#\n",
    "################################################\n",
    "    \n",
    "def getGlzsm(discritizedArray, connection):\n",
    "    m = discritizedArray\n",
    "    if len(m.shape) == 2:\n",
    "        if connection == 4:\n",
    "            s = [[0,1,0],[1,1,1],[0,1,0]]\n",
    "        elif connection == 8:\n",
    "            s = [[1]*3]*3\n",
    "        else:\n",
    "            raise ValueError('connection must be 4 or 8 in case of 2-dimensional.')\n",
    "    elif len(m.shape) == 3:\n",
    "        if connection == 6:\n",
    "            s = [[[0,0,0], [0,1,0], [0,0,0]],\n",
    "                 [[0,1,0], [1,1,1], [0,1,0]],\n",
    "                 [[0,0,0], [0,1,0], [0,0,0]]]\n",
    "        elif connection == 18:\n",
    "            s = [[[0,1,0], [1,1,1], [0,1,0]],\n",
    "                 [[1,1,1], [1,1,1], [1,1,1]],\n",
    "                 [[0,1,0], [1,1,1], [0,1,0]]]\n",
    "        elif connection == 26:\n",
    "            s = [[[1]*3]*3]*3\n",
    "        else:\n",
    "            raise ValueError('connection must be 6 or 18 or 26 in case of 3-dimensional.')\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "    lst = []\n",
    "    maxgl = np.nanmax(m).astype(int)\n",
    "    maxsz = 0\n",
    "    for i in range(maxgl+1):#[2,3]:\n",
    "\n",
    "        m1 = m==i\n",
    "        a,_ = scipy.ndimage.label(m1, s)\n",
    "        if np.sum(a)==0:\n",
    "            continue\n",
    "        b=pd.crosstab(a.flatten(), 0)\n",
    "        c = pd.crosstab(b[1:].values.flatten(), 0)\n",
    "        c.columns = [[i]]\n",
    "        c = c.T\n",
    "\n",
    "        maxsz1 = np.max(c.columns.values)\n",
    "        if maxsz < maxsz1:\n",
    "            maxsz = maxsz1\n",
    "\n",
    "        lst.append(c)\n",
    "    \n",
    "    df = pd.DataFrame(np.zeros((maxgl+1,maxsz+1)), index = np.arange(maxgl+1), columns=np.arange(maxsz+1))\n",
    "    for l in lst:\n",
    "        df = df.add(l, fill_value =0)\n",
    "    df = df.astype(int)\n",
    "    return df\n",
    "\n",
    "def combineGlzsm(discritizedArray, connection):\n",
    "    report('### Generating GLZSM')\n",
    "\n",
    "    m = discritizedArray\n",
    "    df = getGlzsm(m, connection)\n",
    "    report(df)\n",
    "    ps = calcGlrlmParams(df, 'Z')\n",
    "    res = pd.DataFrame([ps])\n",
    "    report(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_getGlzsm():\n",
    "    assert 1==2\n",
    "    \n",
    "    # 果たしてold versionのpythonではdf.astype(int)のところでそもそもnanが出てこないのか。\n",
    "\n",
    "    \n",
    "def test_combineGlzsm():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "test_getGlzsm()\n",
    "test_combineGlzsm()\n",
    "\n",
    "print('No error.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# neighborhood gray-level different matrix in Python\n",
    "# Kenji Hirata, 11/27/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def getNgldm(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    if len(m.shape) == 2:\n",
    "        return getNgldm2d(discritizedArray, mode)\n",
    "    elif len(m.shape) == 3:\n",
    "        return getNgldm3d(discritizedArray, mode)\n",
    "    else:\n",
    "        raise ValueError('discritizedArray must be 2- or 3-dimensional.')\n",
    "\n",
    "def getNgldm2d(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    ny,nx = m.shape\n",
    "    \n",
    "    #fill periphery with numpy.nan\n",
    "    nx+=2\n",
    "    ny+=2\n",
    "    m1 = np.empty((ny,nx))\n",
    "    m1.fill(np.nan)\n",
    "    m1[1:-1,1:-1] = m\n",
    "    m = m1\n",
    "\n",
    "    se = pd.Series()\n",
    "    for i in range(int(np.nanmax(m)+1)):\n",
    "        #print('i =',i)\n",
    "        avelist = []\n",
    "        for y in range(1,ny-1):\n",
    "            for x in range(1,nx-1):\n",
    "                if np.isnan(m[y,x]) == False:\n",
    "                    if m[y,x] == i:\n",
    "                        neighbors = [m[y-1,x-1], m[y-1,x  ], m[y-1,x+1],\n",
    "                                     m[y  ,x-1],             m[y  ,x+1],\n",
    "                                     m[y+1,x-1], m[y+1,x  ], m[y+1,x+1]]\n",
    "                        if mode == 1:\n",
    "                            ave = np.nanmean(neighbors)\n",
    "                        elif mode == 2:\n",
    "                            ave = np.mean(neighbors)\n",
    "                        #print(x,y,'ave =',ave)\n",
    "                        avelist.append(np.abs(i - ave))\n",
    "        sum = np.nansum(avelist) # not mean but sum\n",
    "        se1 = pd.Series({i:sum})\n",
    "        se = se.append(se1)\n",
    "    return se\n",
    "\n",
    "def getNgldm3d(discritizedArray, mode):\n",
    "    m = discritizedArray\n",
    "    nz,ny,nx = m.shape\n",
    "    \n",
    "    #fill periphery with numpy.nan\n",
    "    nz+=2\n",
    "    ny+=2\n",
    "    nx+=2    \n",
    "    m1 = np.empty((nz,ny,nx))\n",
    "    m1.fill(np.nan)\n",
    "    m1[1:-1,1:-1,1:-1] = m\n",
    "    m = m1\n",
    "\n",
    "    se = pd.Series()\n",
    "    for i in range(int(np.nanmax(m)+1)):\n",
    "        avelist = []\n",
    "        for z in range(1,nz-1):\n",
    "            for y in range(1,ny-1):\n",
    "                for x in range(1,nx-1):\n",
    "                    if np.isnan(m[z,y,x]) == False:\n",
    "                        if m[z,y,x] == i:\n",
    "                            neighbors = [m[z-1,y-1,x-1], m[z-1,y-1,x  ], m[z-1,y-1,x+1],\n",
    "                                         m[z-1,y  ,x-1], m[z-1,y  ,x  ], m[z-1,y  ,x+1],\n",
    "                                         m[z-1,y+1,x-1], m[z-1,y+1,x  ], m[z-1,y+1,x+1],\n",
    "                                         m[z  ,y-1,x-1], m[z  ,y-1,x  ], m[z  ,y-1,x+1],\n",
    "                                         m[z  ,y  ,x-1],                 m[z  ,y  ,x+1],\n",
    "                                         m[z  ,y+1,x-1], m[z  ,y+1,x  ], m[z  ,y+1,x+1],\n",
    "                                         m[z+1,y-1,x-1], m[z+1,y-1,x  ], m[z+1,y-1,x+1],\n",
    "                                         m[z+1,y  ,x-1], m[z+1,y  ,x  ], m[z+1,y  ,x+1],\n",
    "                                         m[z+1,y+1,x-1], m[z+1,y+1,x  ], m[z+1,y+1,x+1]]\n",
    "                            if mode == 1:\n",
    "                                ave = np.nanmean(neighbors)\n",
    "                            elif mode == 2:\n",
    "                                ave = np.mean(neighbors)\n",
    "                            avelist.append(np.abs(i - ave))\n",
    "        sum = np.nansum(avelist) # not mean but sum\n",
    "        se1 = pd.Series({i:sum})\n",
    "        se = se.append(se1)\n",
    "    return se\n",
    "\n",
    "\n",
    "def calcNgldmParams(discritizedArray, ngldm, nbin):\n",
    "    \n",
    "    p1 = pd.crosstab(discritizedArray.ravel(),0)\n",
    "    p = complement_crosstab2(p1, nbin).values.ravel()\n",
    "    N = np.sum(p)\n",
    "    p = p/N\n",
    "    \n",
    "    s = complement_crosstab2(pd.DataFrame(ngldm), nbin).values.ravel()\n",
    "\n",
    "    jj = np.tile(np.arange(nbin),(nbin,1))\n",
    "    ii = jj.T\n",
    "\n",
    "    report('NGLDM')\n",
    "    report(s)\n",
    "    report('probability')\n",
    "    report(p)\n",
    "\n",
    "    Coarseness = 1 / (1e-20 + np.sum(p*s))\n",
    "\n",
    "    Contrast = np.sum(np.outer(p,p) * (ii-jj)**2) * np.sum(s) / (N*nbin*(nbin-1))\n",
    "    \n",
    "    #busyness\n",
    "    total = 0\n",
    "    for i in range(len(p)):\n",
    "        for j in range(len(p)):\n",
    "            if not(p[i]==0) and not(p[j]==0):\n",
    "                total += np.abs(i * p[i] - j * p[j])\n",
    "    Busyness = np.sum(p*s) / total\n",
    "\n",
    "    se = pd.Series([Coarseness,Contrast,Busyness], ['CoarsenessNGLDM','ContrastNGLDM','BusynessNGLDM'])\n",
    "    return pd.DataFrame([se])\n",
    "\n",
    "def combineNgldm(mat, nbin, mode):\n",
    "    report('### Generating NGLDM')\n",
    "    ngldm = getNgldm(mat, mode)\n",
    "    res = calcNgldmParams(mat, ngldm, nbin)\n",
    "    report(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def test_getNgldm():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "def test_getNgldm2d():\n",
    "    assert 1==2\n",
    "    \n",
    "\n",
    "def test_getNgldm3d():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "def test_calcNgldmParams():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "def test_combineNgldm():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "test_getNgldm()\n",
    "test_getNgldm2d()\n",
    "test_getNgldm3d()\n",
    "test_calcNgldmParams()\n",
    "test_combineNgldm()\n",
    "\n",
    "    \n",
    "print('No error.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# Get all params\n",
    "# Takes DataFrame with columns of x,y,v --- v is continuous\n",
    "#       nbin = 16, 32, 64, etc\n",
    "# Returns DataFrame\n",
    "#\n",
    "# Kenji Hirata, 11/27/2017\n",
    "#\n",
    "################################################\n",
    "\n",
    "def getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    results.append(usualParams(df.v))\n",
    "    \n",
    "    df['v1'] = discritize(df.v, nbin, lo, hi)\n",
    "    results.append(histParams(df.v1))\n",
    "    \n",
    "    results.append(comatParams2d(df, nbin)) # comatParams requires v1 columns, which is discreted version of v.\n",
    "    \n",
    "    mat = generate_2darray_v1(df)\n",
    "    results.append(combineGlrlm(mat))\n",
    "    \n",
    "    results.append(combineGlzsm(mat, connection))\n",
    "    \n",
    "    results.append(combineNgldm(mat, nbin, ngldm_mode))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    results.append(usualParams(df.v))\n",
    "    \n",
    "    df['v1'] = discritize(df.v, nbin, lo, hi)\n",
    "    results.append(histParams(df.v1))\n",
    "    \n",
    "    results.append(comatParams3d(df, nbin)) # comatParams requires v1 columns, which is discreted version of v.\n",
    "    \n",
    "    mat = generate_3darray_v1(df)\n",
    "               \n",
    "    results.append(combineGlrlm(mat))\n",
    "    \n",
    "    results.append(combineGlzsm(mat, connection))\n",
    "\n",
    "    results.append(combineNgldm(mat, nbin, ngldm_mode))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def test_getAllParams2d():\n",
    "    assert 1==2\n",
    "\n",
    "    \n",
    "def test_getAllParams3d():\n",
    "    assert 1==2\n",
    "    \n",
    "\n",
    "test_getAllParams2d()\n",
    "test_getAllParams3d()\n",
    "\n",
    "print('No error.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# Convert ugly table to pretty table\n",
    "# Takes list of DataFrame\n",
    "# Returns DataFrame\n",
    "#\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "################################################\n",
    "\n",
    "\n",
    "def convertToPrettyTable(res):\n",
    "    res1 = []\n",
    "    for r in res:\n",
    "        if len(r)==1:\n",
    "            res1.append(r)\n",
    "        else:\n",
    "            s = r.iloc[-1,:]\n",
    "            d = pd.DataFrame([s], index=[0])\n",
    "            res1.append(d)\n",
    "    return pd.concat(res1, axis=1)\n",
    "\n",
    "def convertToPrettyTable2(res):\n",
    "    res1 = []\n",
    "    for r in res:\n",
    "        if len(r)==1:\n",
    "            res1.append(r)\n",
    "        else:\n",
    "            res1.append(stack1(r))\n",
    "    return pd.concat(res1, axis=1)\n",
    "\n",
    "\n",
    "def stack1(df):\n",
    "    b=df.stack()\n",
    "\n",
    "    def f(s):\n",
    "        return str(s).replace('(','').replace(')','').replace(' ','').replace(',','')\n",
    "\n",
    "    return pd.DataFrame([b.values], columns= [ind[1]+f(ind[0]) for ind in b.index])\n",
    "\n",
    "\n",
    "###################################################\n",
    "#\n",
    "# Super batch for texture analyses in Python\n",
    "# Kenji Hirata, 1/2/2018\n",
    "#\n",
    "###################################################\n",
    "\n",
    "\n",
    "def superBatch(di, dim, nbin, lo, hi, connection, ngldm_mode, full = False):\n",
    "\n",
    "    filenames = os.listdir(di)\n",
    "\n",
    "    print(\"Files:\", filenames)\n",
    "    lst = []\n",
    "    for f in filenames:\n",
    "        print(str(datetime.datetime.now()), f)\n",
    "        \n",
    "        fullname = os.path.join(di,f)\n",
    "        \n",
    "        df = pd.read_csv(fullname, delimiter='\\t')\n",
    "        \n",
    "        \n",
    "        ##### temporary code\n",
    "        ###df.columns = ['x','y','z','v']\n",
    "        #####\n",
    "\n",
    "        if dim==2:\n",
    "            results = getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        elif dim==3:\n",
    "            results = getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        else:\n",
    "            raise ValueError('dim (dimension) must be 2 or 3.')\n",
    "            \n",
    "        if full:\n",
    "            results_pretty = convertToPrettyTable2(results)\n",
    "        else:\n",
    "            results_pretty = convertToPrettyTable(results)\n",
    "        \n",
    "        #print(results_pretty.T)\n",
    "        \n",
    "        results_pretty.index = [f]\n",
    "        \n",
    "        lst.append(results_pretty)\n",
    "\n",
    "    results_final = pd.concat(lst)\n",
    "    return results_final\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "#\n",
    "# Super batch 2 for texture analyses in Python\n",
    "# Kenji Hirata, 12/22/2017\n",
    "#\n",
    "###################################################\n",
    "\n",
    "\n",
    "def superBatch2(di, dim, nbin, lo, hi, connection, ngldm_mode):\n",
    "\n",
    "    filenames = os.listdir(di)\n",
    "\n",
    "    print(\"Files:\", filenames)\n",
    "    lst = []\n",
    "    for f in filenames:\n",
    "        print(str(datetime.datetime.now()))\n",
    "        print(f)\n",
    "        \n",
    "        fullname = os.path.join(di,f)\n",
    "        \n",
    "        df = pd.read_csv(fullname, delimiter='\\t')\n",
    "        \n",
    "        \n",
    "        ##### temporary code\n",
    "        \n",
    "        df.rename(columns = {'v1':'v'}, inplace=True)\n",
    "        df = df[['x','y','z','v']]\n",
    "        #print(df)\n",
    "        \n",
    "        #df.columns = ['roinum','x','y','z','v','fmiso','gd','flair']\n",
    "        #####\n",
    "\n",
    "        if dim==2:\n",
    "            results = getAllParams2d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        elif dim==3:\n",
    "            results = getAllParams3d(df, nbin, lo, hi, connection, ngldm_mode)\n",
    "        else:\n",
    "            raise ValueError('dim (dimension) must be 2 or 3.')\n",
    "            \n",
    "        results_pretty = convertToPrettyTable(results)\n",
    "        print(results_pretty.T)\n",
    "        \n",
    "        results_pretty.index = [f]\n",
    "        \n",
    "        lst.append(results_pretty)\n",
    "\n",
    "    results_final = pd.concat(lst)\n",
    "    return results_final\n",
    "\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = r'JSAWI2018demo1'\n",
    "df = superBatch(di, dim = 3, nbin = 64, lo = 0, hi = 20, connection = 26, ngldm_mode = 1)\n",
    "df.to_excel('jsawi2018.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = r'JSAWI2018demo'\n",
    "df = superBatch(di, dim = 3, nbin = 64, lo = 0, hi = 20, connection = 26, ngldm_mode = 1)\n",
    "df.to_excel('jsawi2018.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Template for Running ptexture\n",
    "\n",
    "\n",
    "# This indicates the directory where you have file(s) of x,y,z,v text.\n",
    "di = r'testdata'\n",
    "\n",
    "# Run\n",
    "# dim (dimention) is 2 or 3. 2 for polar map; 3 for volume data.\n",
    "# nbin is number of discritization bin, usually 64\n",
    "# lo and hi specifies lower and upper limit used for discritization\n",
    "#   if lo = np.nan and hi = np.nan, the global min and max are used for lo and hi.\n",
    "# connection must be 2 or 4 for 2-d, and 6, 18, or 26 for 3-d (detail will be explained later)\n",
    "# ngldm_mode = 1 uses np.nanmean(), mode == 2 uses np.mean() to calculate NGLDM\n",
    "df = superBatch(di, dim = 3, nbin = 64, lo = 0, hi = 20, connection = 26, ngldm_mode = 1)\n",
    "df.to_excel('result_file_name.xlsx')\n",
    "\n",
    "# min-max case\n",
    "#df = superBatch(di, dim = 3, nbin = 64, lo = np.nan, hi = np.nan, connection = 26, ngldm_mode = 1)\n",
    "#df.to_excel('result_file_name_minmax.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
